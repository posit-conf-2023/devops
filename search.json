[
  {
    "objectID": "supplemental_materials/linux_exercises_files/linux_exercises.html",
    "href": "supplemental_materials/linux_exercises_files/linux_exercises.html",
    "title": "Linux exercises",
    "section": "",
    "text": "Login to play with docker using your docker hub credentials.\nAdd an instance to your session."
  },
  {
    "objectID": "supplemental_materials/linux_exercises_files/linux_exercises.html#setup",
    "href": "supplemental_materials/linux_exercises_files/linux_exercises.html#setup",
    "title": "Linux exercises",
    "section": "",
    "text": "Login to play with docker using your docker hub credentials.\nAdd an instance to your session."
  },
  {
    "objectID": "supplemental_materials/linux_exercises_files/linux_exercises.html#exercises",
    "href": "supplemental_materials/linux_exercises_files/linux_exercises.html#exercises",
    "title": "Linux exercises",
    "section": "Exercises",
    "text": "Exercises\n\nIdentify the user that you are logged in as.\nwhoami\nIdentify the linux distribution of your instance.\ncat /etc/*-release\nUse a single command to list the directories that are on the server and save the list as a txt file called directories.txt. Use cat to inspect the text file.\n$ ls -la &gt; directories.txt\nExplore the directories and files using cd, pwd, and ls -la. What is missing in this Linux server based on this article?\nAlpine images tend to be quite small without all the files and directories that we need. Lets pull in a more recent Ubuntu linux image. Go to Docker Hub and find the command to pull the latest version of Ubuntu linux. Make sure to use the Docker Official Image. (We will be going into much more depth later on how Docker images and containers work).\n# https://hub.docker.com/_/ubuntu/tags\ndocker pull ubutu:latest\n\n# use this command to see what images have been pulled\ndocker image list \nRun the container interactively with docker run -it ubuntu and re-run exercises 1 through 4 to inspect the new directory structure.\nChange directories to your root directory and then create 2 folders titles test1 and test2.\ncd ~\nmkdir test1 test2\nCreate a new user with the adduser command and enter in the requested information. Identify which groups currently exist in the system. Add your new user to the root group and then switch to that new user.\nadduser rika\n\n# Adding user `rika' ...\n# Adding new group `rika' (1000) ...\n# Adding new user `rika' (1000) with group `rika' ...\n# Creating home directory `/home/rika' ...\n# Copying files from `/etc/skel' ...\n# New password: \n# Retype new password: \n# passwd: password updated successfully\n# Changing the user information for rika\n# Enter the new value, or press ENTER for the default\n       #  Full Name []: Rika\n       #  Room Number []: \n       #  Work Phone []: \n       # Home Phone []: \n       # Other []: \n# Is the information correct? [Y/n] Y\n\ngroups\nusermod -aG root rika \nsu rika\n# use ctrl + d to exit back to root\n\ncd between the root directory and the home directory of your new user to understand how user home directories are stored in a linux file system.\n# the tilde is a shortcut to the home directory of the signed in user\ncd ~ \npwd\ncd /\npwd\nLets do some updates for our server.\n# update packages\napt-get update\n# add sudo which temporarily elevates privileges allowing users to complete sensitive tasks without logging in as the root user\napt-get install sudo\n# add your user to the sudoers group\nusermod -aG sudo rika"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DevOps for Data Scientists",
    "section": "",
    "text": ":spiral_calendar: September 17 and 18, 2023\n:alarm_clock: 09:00 - 17:00\n:hotel: ROOM TBD\n:writing_hand: pos.it/conf\n\n\n\n\n\n\n\nhttps://community.rstudio.com/t/devops-for-data-scientists-workshop-posit-conf-2023/171829\n\n\n\n\nSlides\nCode for Slides\nLab instructions\nLab example code\n\n\n\n\n\n\n\n\n\n\n\n\n\nADD INSTRUCTOR BIO\n\n This work is licensed under a Creative Commons Attribution 4.0 International License."
  },
  {
    "objectID": "index.html#pre-work",
    "href": "index.html#pre-work",
    "title": "DevOps for Data Scientists",
    "section": "",
    "text": "https://community.rstudio.com/t/devops-for-data-scientists-workshop-posit-conf-2023/171829"
  },
  {
    "objectID": "index.html#materials",
    "href": "index.html#materials",
    "title": "DevOps for Data Scientists",
    "section": "",
    "text": "Slides\nCode for Slides\nLab instructions\nLab example code"
  },
  {
    "objectID": "index.html#instructor",
    "href": "index.html#instructor",
    "title": "DevOps for Data Scientists",
    "section": "",
    "text": "ADD INSTRUCTOR BIO\n\n This work is licensed under a Creative Commons Attribution 4.0 International License."
  },
  {
    "objectID": "coursework_labs/02_lab_docker/Exercises.html",
    "href": "coursework_labs/02_lab_docker/Exercises.html",
    "title": "Lab: Docker",
    "section": "",
    "text": "Create a dockerhub username and password\n\nUsing your Docker hub username and password, login to https://labs.play-with-docker.com/\nClick + ADD NEW INSTANCE\nCongratulations! You are now in an Alpine Linux instance directly on your browser. Check this by running cat /etc/*-release in the command line interface.\n\n\n\n\n\n\n\nNote\n\n\n\nYour terminal should say something like [node1] (local) root@123.123.0.12 If it doesn’t refresh your screen or add another instance.\n\n\n\n\n\nThe basic docker run command takes this form:\ndocker run [OPTIONS] [IMAGE:TAG] [COMMAND] [ARG...]\nIn the below exercise we will practice running docker containers with different options or “flags.”\n\nCurrently we have no docker images downloaded. Confirm this with docker image ls -a.\n\nPull down a Dockerhub linux image. Confirm that the image is downloaded with the ls command.\n\ndocker pull ubuntu\ndocker image ls -a\n\nRun an interactive container with the bash shell attached. Run a few linux commands to explore your environment and then exit the container.\n\ndocker run -it ubuntu bash\nls\nwhoami\nhostname\n# exit the container with Ctrl+D or exit\nThis runs the container in the foreground so you are unable to access the command prompt for your original alpine server. For this reason interactive mode is often used for development and testing.\n\nRun the container in detached mode and then list all your containers.\n\ndocker run -d ubuntu\ndocker container ls -a\nYou should see that the ubuntu container was created and then exited. The container ID is shown with an exited status and the command line is still accessible.\nDetached containers run in the background, so the container keeps running until the application process exits (which is what happened here), or you stop the container. For this reason detached mode is often used for production purposes.\n\nRun an nginx web server in detached mode to see what happens when the process doesnt just exit. The image will be automatically pulled from Dockerhub if it is not found locally so there is no need to run docker pull first.\n\ndocker run -d -P --name nginx1 nginx:alpine\n\n# -P publishes network ports so you can send traffic into the container\n# --name gives the container a name so you can work with it in other commands\nClick on the port button at the top of your page and enter 32768.\n\nThis should bring you to the nginx server.\n\n\nExamine your container and then stop it.\n\n# check your running containers\ndocker container ls -a\n\n# you can also check your running processes\ndocker ps -a\n\n# stop the container using its name\ndocker container stop nginx1\n\nRun a container with a different linux distro and then automatically remove it. Add an echo command to confirm that the container has actually run.\n\ndocker run --rm debian echo \"hello world\"\nThis mode is usually used on foreground containers that perform short-term tasks such as tests or database backups. Since a container is ephemeral, once it is removed anything you may have downloaded or created in the container is also destroyed.\nCheck to see that the container was completely removed. You shouldnt see the debian container in the output at all.\ndocker container ls -a\n\n\n\nThe docker exec command is very similar to the docker run -it command. Both are very helpful for debugging containers as they allow you to jump inside your container instance. The exec command needs a running container to execute any command, whereas the -it flag starts a container and places you into a terminal in interactive mode. Use the docker exec command to execute a bash command in a running container. This can be used to execute any command within a running container.\ndocker exec requires two arguments - the container and the command you want to run.\ndocker exec [OPTIONS] CONTAINER [COMMAND] [ARG...]\n\nUse docker run -it to jump into an ubuntu container.\n\ndocker run -it -d ubuntu\nexit\n\nUse docker exec to run commands in a container\n\ndocker container ls -a # to get a container ID of a running container\ndocker exec -it CONTAINER_ID bash\nexit\ndocker exec CONTAINER_ID ls \n\nLets run a detached MySQL container and then check out some logs. The database requires a password to work.In production you should never pass credentials directly in your command but we will do it for testing purposes. (The forward slashes below allow you to use a new line for your code)\n\n docker container run -d --name mydb \\\n --name mydb \\\n -e MYSQL_ROOT_PASSWORD=my-secret-pw \\ \n mysql\n \ndocker container logs mydb\n\n\n\n\nPull two versions of the same image\n\ndocker pull httpd:alpine\ndocker pull httpd:latest\n\nInspect ports.\n\ndocker inspect  httpd:latest\ndocker inspect  httpd:alpine\n\nMap two different host ports to the same application port for the two containers.\n\ndocker run -d -p 81:80 --name httpd-latest httpd:latest\ndocker run -d -p 80:80 --name httpd-alpine httpd:alpine\ndocker ps\n\n\n\n\nStop your running containers with docker stop and return to your original command prompt.\nCreate a text file.\n\ntouch test.txt # create a text file\necho \"this is a test file\" &gt; test.txt # redirect string to the file\ncat test.txt # confirm that the echo command worked\n\nWe want to add this file from our host machine into a separate Ubuntu container.\n\npwd # to see where the test.txt file is located on your host machine\n\ndocker run -it -d -v /root:/data ubuntu # mount a shared volume to a folder in the container called \"data\"\n\ndocker exec -it CONTAINER_ID bash\n\nls # see what folders are in the container\n\ncd data # move to the newly created data directory\n\nls # confirm that the text file is there\nIn order to get data in or out of a container, you need to mount a shared volume (directory) between the container and host with the -v flag. You specify a host directory and a container directory separated by :. Anything in the volume will be available to both the host and the container at the file paths specified.\n\n\n\n\nExit out of your container from the previous exercise with exit and confirm that the container is still running. This container should have the new directory and text file.\nRun docker diff CONTAINER_ID to see the difference between the base image and the new container. You should see the new data folder,\nLogin to docker hub in your instance using docker login and enter your username and password.\nCommit the changed ubuntu image and give it a new name like ubuntu_text.\n\ndocker commit CONTAINER_ID ubuntu_text\ndocker image ls # to check the new image is available\n\nTag and push the image to dockerhub. Login to docker hub to see your saved and shareable image!\n\ndocker tag ubuntu_text docker_hub_username/ubuntu_text\ndocker push docker_hub_username/ubuntu_text\n\n\n\nBest practice is to create a Dockerfile so that any changes to your image can be documented.\n\nCreate a Dockerfile (no file extension needed)in your instance with touch Dockerfile and add the following to it.\n\ntouch Dockerfile\nvim Dockerfile\n# press i to enter insert mode\n\nFROM rocker/shiny:4.3.1\nCMD [\"/usr/bin/shiny-server\"]\n\n# press escape \n:wq # to save and exit\n\nBuild the image with docker build -t my_server . where my_server is the name of your new image\nRun your container with docker run -d -p 3838:3838 my_server\n\nthe -p flag maps a port from the host to a port in the container.\nthis gives us the ability to access the services running inside the container\nexample: `-p 8080:80` maps port 8080 on the host to port 80 in the container.\nin our code we use port 3838 because that is the port that Shiny Server uses by default.\n\nA port number will appear - click on it to access the home page of Shiny Server!\n\n\n\nYou should see something like this:\n\nWe want to change the home page and have it show an app of our choosing instead. Exec into your container and let’s find where the information for the home page is stored.\n\n# get the container ID or name \ndocker container ls \n\n# execute into the bash shell in your container\ndocker exec -it CONTAINER_ID bash \n\n# list your folders\nls \n\n#this will show you all the server executables for basic shell commands. See if you can find those you've used like touch\ncd usr/bin \nls\n\n# look at the code for the home page,. Notice where the sample \"It's Alive\" and \"Shiny Doc\" apps on the home page are being pulled from\ncd /srv/shiny-server \nls\ncat index.html \n\n# look at the configuration file for the server\ncd /etc/shiny-server\ncat shiny-server.conf \n\nLet’s delete the home page and the sample apps in the server.\n\nsudo rm /srv/shiny-server/index.html\nsudo rm -rf /srv/shiny-server/sample-apps\n# refresh your shiny server webpage\nNotice how the server home page now has a directory of the apps that live in /srv/shiny-server. Recall how the configuration file had directory_index turned on.\n\nLet’s create a basic shiny app and then rebuild our image. We will move our app to the server in our Dockerfile instead of on the fly in our run command.\n\nexit\ndocker container ls \ndocker container stop CONTAINER_IT \nmkdir apps\ncd apps\ntouch app.R\nvim app.R\n# press i to insert the following code\n\nlibrary(shiny)\n\n# Define UI for application that draws a histogram\nui &lt;- fluidPage(\n\n    # Application title\n    titlePanel(\"Old Faithful Geyser Data\"),\n\n    # Sidebar with a slider input for number of bins \n    sidebarLayout(\n        sidebarPanel(\n            sliderInput(\"bins\",\n                        \"Number of bins:\",\n                        min = 1,\n                        max = 50,\n                        value = 30)\n        ),\n\n        # Show a plot of the generated distribution\n        mainPanel(\n           plotOutput(\"distPlot\")\n        )\n    )\n)\n\n# Define server logic required to draw a histogram\nserver &lt;- function(input, output) {\n\n    output$distPlot &lt;- renderPlot({\n        # generate bins based on input$bins from ui.R\n        x    &lt;- faithful[, 2]\n        bins &lt;- seq(min(x), max(x), length.out = input$bins + 1)\n\n        # draw the histogram with the specified number of bins\n        hist(x, breaks = bins, col = 'darkgray', border = 'white',\n             xlab = 'Waiting time to next eruption (in mins)',\n             main = 'Histogram of waiting times')\n    })\n}\n\n# Run the application \nshinyApp(ui = ui, server = server)\n\n# press escape \n:wq to save \n\n##docker run -d -p 3838:3838 -v ./apps:/srv/shinyapps my_server # my_server is the name of the docker image that you built\n\nUpdate our Dockerfile\n\ncd /root\nvim Dockerfile\n# press i to insert code\n\nFROM rocker/shiny:4.3.1\n# comes preinstalled with a bunch of packages\n\nRUN apt-get update && apt-get install -y \\\n    libcurl4-gnutls-dev \\\n    libssl-dev\n\nRUN R -e \"install.packages(('palmerpenguins'), \\\n    repos = 'https://packagemanager.posit.co/cran/__linux__/jammy/latest')\"\n\nCOPY ./apps/* /srv/shiny-server/\n\nCMD [\"/usr/bin/shiny-server\"]\n\nRebuild the dockerfile with a new name\n\ndocker build -t new_app\n\nRun the container\n\ndocker run -d -p 3838:3838 new_app"
  },
  {
    "objectID": "coursework_labs/02_lab_docker/Exercises.html#goals",
    "href": "coursework_labs/02_lab_docker/Exercises.html#goals",
    "title": "Lab: Docker",
    "section": "",
    "text": "Create a dockerhub username and password\n\nUsing your Docker hub username and password, login to https://labs.play-with-docker.com/\nClick + ADD NEW INSTANCE\nCongratulations! You are now in an Alpine Linux instance directly on your browser. Check this by running cat /etc/*-release in the command line interface.\n\n\n\n\n\n\n\nNote\n\n\n\nYour terminal should say something like [node1] (local) root@123.123.0.12 If it doesn’t refresh your screen or add another instance.\n\n\n\n\n\nThe basic docker run command takes this form:\ndocker run [OPTIONS] [IMAGE:TAG] [COMMAND] [ARG...]\nIn the below exercise we will practice running docker containers with different options or “flags.”\n\nCurrently we have no docker images downloaded. Confirm this with docker image ls -a.\n\nPull down a Dockerhub linux image. Confirm that the image is downloaded with the ls command.\n\ndocker pull ubuntu\ndocker image ls -a\n\nRun an interactive container with the bash shell attached. Run a few linux commands to explore your environment and then exit the container.\n\ndocker run -it ubuntu bash\nls\nwhoami\nhostname\n# exit the container with Ctrl+D or exit\nThis runs the container in the foreground so you are unable to access the command prompt for your original alpine server. For this reason interactive mode is often used for development and testing.\n\nRun the container in detached mode and then list all your containers.\n\ndocker run -d ubuntu\ndocker container ls -a\nYou should see that the ubuntu container was created and then exited. The container ID is shown with an exited status and the command line is still accessible.\nDetached containers run in the background, so the container keeps running until the application process exits (which is what happened here), or you stop the container. For this reason detached mode is often used for production purposes.\n\nRun an nginx web server in detached mode to see what happens when the process doesnt just exit. The image will be automatically pulled from Dockerhub if it is not found locally so there is no need to run docker pull first.\n\ndocker run -d -P --name nginx1 nginx:alpine\n\n# -P publishes network ports so you can send traffic into the container\n# --name gives the container a name so you can work with it in other commands\nClick on the port button at the top of your page and enter 32768.\n\nThis should bring you to the nginx server.\n\n\nExamine your container and then stop it.\n\n# check your running containers\ndocker container ls -a\n\n# you can also check your running processes\ndocker ps -a\n\n# stop the container using its name\ndocker container stop nginx1\n\nRun a container with a different linux distro and then automatically remove it. Add an echo command to confirm that the container has actually run.\n\ndocker run --rm debian echo \"hello world\"\nThis mode is usually used on foreground containers that perform short-term tasks such as tests or database backups. Since a container is ephemeral, once it is removed anything you may have downloaded or created in the container is also destroyed.\nCheck to see that the container was completely removed. You shouldnt see the debian container in the output at all.\ndocker container ls -a\n\n\n\nThe docker exec command is very similar to the docker run -it command. Both are very helpful for debugging containers as they allow you to jump inside your container instance. The exec command needs a running container to execute any command, whereas the -it flag starts a container and places you into a terminal in interactive mode. Use the docker exec command to execute a bash command in a running container. This can be used to execute any command within a running container.\ndocker exec requires two arguments - the container and the command you want to run.\ndocker exec [OPTIONS] CONTAINER [COMMAND] [ARG...]\n\nUse docker run -it to jump into an ubuntu container.\n\ndocker run -it -d ubuntu\nexit\n\nUse docker exec to run commands in a container\n\ndocker container ls -a # to get a container ID of a running container\ndocker exec -it CONTAINER_ID bash\nexit\ndocker exec CONTAINER_ID ls \n\nLets run a detached MySQL container and then check out some logs. The database requires a password to work.In production you should never pass credentials directly in your command but we will do it for testing purposes. (The forward slashes below allow you to use a new line for your code)\n\n docker container run -d --name mydb \\\n --name mydb \\\n -e MYSQL_ROOT_PASSWORD=my-secret-pw \\ \n mysql\n \ndocker container logs mydb\n\n\n\n\nPull two versions of the same image\n\ndocker pull httpd:alpine\ndocker pull httpd:latest\n\nInspect ports.\n\ndocker inspect  httpd:latest\ndocker inspect  httpd:alpine\n\nMap two different host ports to the same application port for the two containers.\n\ndocker run -d -p 81:80 --name httpd-latest httpd:latest\ndocker run -d -p 80:80 --name httpd-alpine httpd:alpine\ndocker ps\n\n\n\n\nStop your running containers with docker stop and return to your original command prompt.\nCreate a text file.\n\ntouch test.txt # create a text file\necho \"this is a test file\" &gt; test.txt # redirect string to the file\ncat test.txt # confirm that the echo command worked\n\nWe want to add this file from our host machine into a separate Ubuntu container.\n\npwd # to see where the test.txt file is located on your host machine\n\ndocker run -it -d -v /root:/data ubuntu # mount a shared volume to a folder in the container called \"data\"\n\ndocker exec -it CONTAINER_ID bash\n\nls # see what folders are in the container\n\ncd data # move to the newly created data directory\n\nls # confirm that the text file is there\nIn order to get data in or out of a container, you need to mount a shared volume (directory) between the container and host with the -v flag. You specify a host directory and a container directory separated by :. Anything in the volume will be available to both the host and the container at the file paths specified.\n\n\n\n\nExit out of your container from the previous exercise with exit and confirm that the container is still running. This container should have the new directory and text file.\nRun docker diff CONTAINER_ID to see the difference between the base image and the new container. You should see the new data folder,\nLogin to docker hub in your instance using docker login and enter your username and password.\nCommit the changed ubuntu image and give it a new name like ubuntu_text.\n\ndocker commit CONTAINER_ID ubuntu_text\ndocker image ls # to check the new image is available\n\nTag and push the image to dockerhub. Login to docker hub to see your saved and shareable image!\n\ndocker tag ubuntu_text docker_hub_username/ubuntu_text\ndocker push docker_hub_username/ubuntu_text\n\n\n\nBest practice is to create a Dockerfile so that any changes to your image can be documented.\n\nCreate a Dockerfile (no file extension needed)in your instance with touch Dockerfile and add the following to it.\n\ntouch Dockerfile\nvim Dockerfile\n# press i to enter insert mode\n\nFROM rocker/shiny:4.3.1\nCMD [\"/usr/bin/shiny-server\"]\n\n# press escape \n:wq # to save and exit\n\nBuild the image with docker build -t my_server . where my_server is the name of your new image\nRun your container with docker run -d -p 3838:3838 my_server\n\nthe -p flag maps a port from the host to a port in the container.\nthis gives us the ability to access the services running inside the container\nexample: `-p 8080:80` maps port 8080 on the host to port 80 in the container.\nin our code we use port 3838 because that is the port that Shiny Server uses by default.\n\nA port number will appear - click on it to access the home page of Shiny Server!\n\n\n\nYou should see something like this:\n\nWe want to change the home page and have it show an app of our choosing instead. Exec into your container and let’s find where the information for the home page is stored.\n\n# get the container ID or name \ndocker container ls \n\n# execute into the bash shell in your container\ndocker exec -it CONTAINER_ID bash \n\n# list your folders\nls \n\n#this will show you all the server executables for basic shell commands. See if you can find those you've used like touch\ncd usr/bin \nls\n\n# look at the code for the home page,. Notice where the sample \"It's Alive\" and \"Shiny Doc\" apps on the home page are being pulled from\ncd /srv/shiny-server \nls\ncat index.html \n\n# look at the configuration file for the server\ncd /etc/shiny-server\ncat shiny-server.conf \n\nLet’s delete the home page and the sample apps in the server.\n\nsudo rm /srv/shiny-server/index.html\nsudo rm -rf /srv/shiny-server/sample-apps\n# refresh your shiny server webpage\nNotice how the server home page now has a directory of the apps that live in /srv/shiny-server. Recall how the configuration file had directory_index turned on.\n\nLet’s create a basic shiny app and then rebuild our image. We will move our app to the server in our Dockerfile instead of on the fly in our run command.\n\nexit\ndocker container ls \ndocker container stop CONTAINER_IT \nmkdir apps\ncd apps\ntouch app.R\nvim app.R\n# press i to insert the following code\n\nlibrary(shiny)\n\n# Define UI for application that draws a histogram\nui &lt;- fluidPage(\n\n    # Application title\n    titlePanel(\"Old Faithful Geyser Data\"),\n\n    # Sidebar with a slider input for number of bins \n    sidebarLayout(\n        sidebarPanel(\n            sliderInput(\"bins\",\n                        \"Number of bins:\",\n                        min = 1,\n                        max = 50,\n                        value = 30)\n        ),\n\n        # Show a plot of the generated distribution\n        mainPanel(\n           plotOutput(\"distPlot\")\n        )\n    )\n)\n\n# Define server logic required to draw a histogram\nserver &lt;- function(input, output) {\n\n    output$distPlot &lt;- renderPlot({\n        # generate bins based on input$bins from ui.R\n        x    &lt;- faithful[, 2]\n        bins &lt;- seq(min(x), max(x), length.out = input$bins + 1)\n\n        # draw the histogram with the specified number of bins\n        hist(x, breaks = bins, col = 'darkgray', border = 'white',\n             xlab = 'Waiting time to next eruption (in mins)',\n             main = 'Histogram of waiting times')\n    })\n}\n\n# Run the application \nshinyApp(ui = ui, server = server)\n\n# press escape \n:wq to save \n\n##docker run -d -p 3838:3838 -v ./apps:/srv/shinyapps my_server # my_server is the name of the docker image that you built\n\nUpdate our Dockerfile\n\ncd /root\nvim Dockerfile\n# press i to insert code\n\nFROM rocker/shiny:4.3.1\n# comes preinstalled with a bunch of packages\n\nRUN apt-get update && apt-get install -y \\\n    libcurl4-gnutls-dev \\\n    libssl-dev\n\nRUN R -e \"install.packages(('palmerpenguins'), \\\n    repos = 'https://packagemanager.posit.co/cran/__linux__/jammy/latest')\"\n\nCOPY ./apps/* /srv/shiny-server/\n\nCMD [\"/usr/bin/shiny-server\"]\n\nRebuild the dockerfile with a new name\n\ndocker build -t new_app\n\nRun the container\n\ndocker run -d -p 3838:3838 new_app"
  },
  {
    "objectID": "coursework_labs/01_lab_devops_CICD/Deploy_Quarto_GHA.html",
    "href": "coursework_labs/01_lab_devops_CICD/Deploy_Quarto_GHA.html",
    "title": "Lab: Deploy Quarto with GHA",
    "section": "",
    "text": "To get familiar with how the renv package helps create reproducible environments for your R projects.\nTo get comfortable using the terminal for interacting with git and github.\nTo understand how to authenticate to github using SSH or HTTPS.\nTo practice writing and reading a yaml file.\nTo understand the basics of a quarto website.\nTo deploy a quarto site to Github Pages using Github Actions for Continuous Deployment. This will allow you to update your site every time you push a commit to git."
  },
  {
    "objectID": "coursework_labs/01_lab_devops_CICD/Deploy_Quarto_GHA.html#goals",
    "href": "coursework_labs/01_lab_devops_CICD/Deploy_Quarto_GHA.html#goals",
    "title": "Lab: Deploy Quarto with GHA",
    "section": "",
    "text": "To get familiar with how the renv package helps create reproducible environments for your R projects.\nTo get comfortable using the terminal for interacting with git and github.\nTo understand how to authenticate to github using SSH or HTTPS.\nTo practice writing and reading a yaml file.\nTo understand the basics of a quarto website.\nTo deploy a quarto site to Github Pages using Github Actions for Continuous Deployment. This will allow you to update your site every time you push a commit to git."
  },
  {
    "objectID": "coursework_labs/01_lab_devops_CICD/Deploy_Quarto_GHA.html#setup",
    "href": "coursework_labs/01_lab_devops_CICD/Deploy_Quarto_GHA.html#setup",
    "title": "Lab: Deploy Quarto with GHA",
    "section": "Setup",
    "text": "Setup\n\nTo setup your cloud-based development environment create an account using your email at http://rstd.io/class with code angry-beaver. Click on the Rstudio Workbench widget to start your environment.\nClick on + New Session to create a new Rstudio Pro session.\n\n\n\n\n\n\n\nNote\n\n\n\nYou can also set up your project in your local IDE but then you will need to install Quarto and other environment dependencies."
  },
  {
    "objectID": "coursework_labs/01_lab_devops_CICD/Deploy_Quarto_GHA.html#part-1-create-a-local-quarto-website",
    "href": "coursework_labs/01_lab_devops_CICD/Deploy_Quarto_GHA.html#part-1-create-a-local-quarto-website",
    "title": "Lab: Deploy Quarto with GHA",
    "section": "Part 1: Create a local Quarto website",
    "text": "Part 1: Create a local Quarto website\nQuarto is a multi-lingual open-source scientific and technical publishing system that lets you create documents, articles, blogs, websites, and more.\n\nOpen a session in your workbench environment. Give it a name.\nTo create a new website project within RStudio, click on File &gt; New Project &gt; New Directory &gt; Quarto Website and save it to a directory with a name.\n\n\n\n\n\n\n\nquarto site file structure\n\n\n\n\n\n_quarto.yml - project file\nabout.qmd - About page\nindex.qmd - Home page\nstyles.css - custom CSS\n_site - this will be created after you render your files\n\n\n\n\nPress render to see your new website! Or preview via terminal with quarto preview. Make sure that your web browser allows popups. This may take a few moments to install some required packages.\nCreate a repository on github but do not initialize it with a README, license, or gitignore files. This repo will host the files for the site that you will be deploying to Github Pages.\n\nName your repository username.github.io where username is your github username. If you already have this name in use, then name your repo quarto_website\n\nOpen the terminal tab in your Rstudio Workbench environment, cd into your project directory.\nInitialize a local git repository with git init.\nRename your master branch to main so that branch names are consistent across your github repo and your local git. You can use git branch to see what branches exist on your repo and switch between them using git checkout &lt;branch&gt;.\n\n# in your terminal\ngit branch -m master main\n\nConfigure your github information in the terminal. To set your global commit name and email address run the git config command with the --global option:\ngit config --global user.name \"Your Name\"\ngit config --global user.email \"youremail@yourdomain.com\"\ngit config --global init.defaultBranch main\nOnce done, you can confirm that the information is set by running:\ngit config --list\nCreate a .gitignore file in your main directory. Add the following to the file and save:\n\n/.quarto/\n/_site/\n.Rproj.user\n.Rhistory"
  },
  {
    "objectID": "coursework_labs/01_lab_devops_CICD/Deploy_Quarto_GHA.html#part-2-renv-workflow",
    "href": "coursework_labs/01_lab_devops_CICD/Deploy_Quarto_GHA.html#part-2-renv-workflow",
    "title": "Lab: Deploy Quarto with GHA",
    "section": "Part 2: renv workflow",
    "text": "Part 2: renv workflow\n\nExercises:\n\nRun .libPaths() to see your library path\nRun lapply(.libPaths(), list.files) to see what is in your library directory\n\nInstall and initialize an renv workflow.\n\n\n\n\n\n\n\nrenv workflow\n\n\n\n\n\n\nInstall the renv package with install.packages(\"renv\")\nRun renv::init() in your console to initialize a new project-local environment with a private R library and click yes to the prompt.\nChange the title of your site in index.qmd. After you’ve done some work on your code take a snapshot with renv::snapshot()\nRun .libPaths() and lapply(.libPaths(), list.files)again. What has changed?\nRecreate your environment when collaborating or coming back to your work with renv::restore()\n\n\n\n\n\n(Optional) Learning how to use all the power of Quarto is beyond the scope of this workshop but you can use the below resources to pla around with difference templates and designs for your new website.\n\n\n\nhttps://rstudio-conf-2022.github.io/get-started-quarto/materials/06-websites.html#/websites\nhttps://quarto.org/docs/gallery/#websites\nhttps://quarto.org/docs/websites/website-blog.html#themes\nhttps://www.marvinschmitt.com/blog/website-tutorial-quarto/\nhttps://quarto.org/docs/websites/#workflow"
  },
  {
    "objectID": "coursework_labs/01_lab_devops_CICD/Deploy_Quarto_GHA.html#part-3-version-control-and-authentication-with-github",
    "href": "coursework_labs/01_lab_devops_CICD/Deploy_Quarto_GHA.html#part-3-version-control-and-authentication-with-github",
    "title": "Lab: Deploy Quarto with GHA",
    "section": "Part 3: Version Control and Authentication with Github",
    "text": "Part 3: Version Control and Authentication with Github\n\nWe will need to securely authenticate from our server environment to the server that lives on Github. You can do this via two different authentication mechanisms - SSH or HTTPS. Note that there are two urls created for your repo on github- one is for https and the other is for SSH.\n\n\nHTTPSSSH\n\n\nAuthentication:\n\nCopy the https repository URL that you created.\nCreate a classic personal access token and give it permissions to your repository for “repo”, “user”, and “workflow”. Make sure to note your token somewhere safe.\nInstall usethis with install.packages(\"usethis\")\nSave your PAT with\ngitcreds::gitcreds_set()\n\nVersion Control:\n\nAdd your files to local version control with git add . in the terminal.\nCommit your files with git commit -m \"my first commit\"\nUsing the https url from github add your github repository as the “remote” with git remote add origin https://github.com/username/repo_name.git\nPush your local files to github with git push -u origin main where main is the name of your branch in github. You will be prompted for a username and password. Enter your github username and the personal access token from above as your password.\n\nResources: https://docs.github.com/en/migrations/importing-source-code/using-the-command-line-to-import-source-code/adding-locally-hosted-code-to-github\n\n\nAuthentication:\n\nCopy the SSH repository URL that you created.\nGenerate a new SSH key on your server - open the terminal tab in your Rstudio Workbench environment and type ssh-keygen -t ed25519 -C \"your_github_email@example.com\" . Press enter 3 times to leave the file path as the default and to leave the passphrase blank.\nStart the ssh-agent with eval \"$(ssh-agent -s)\". The ssh-agent is a key manager for SSH. It holds your keys and certificates in memory, un-encrypted, and ready for use by ssh.\nCreate a new hidden file (dot files and directories are hidden but you can see them with ls -la) with touch ~/.ssh/config .\nEdit the file using vi or vim and then add your SSH private key to the ssh-agent. Use the cheat sheet below for common vim commands.\n\nvim touch ~/.ssh/config\ni # to get into insert mode\nHost github.com\n  IgnoreUnknown UseKeychain\n  AddKeysToAgent yes\n  UseKeychain yes\n  IdentityFile ~/.ssh/id_ed25519\n# Press the escape key to exit insert mode\n:wq # to save and exit out of the file\nssh-add ~/.ssh/id_ed25519\n\nCopy your public key with cat ~/.ssh/id_ed25519.pub\nIn your Github account go to Settings &gt; SSH and GPG Keys, and add your SSH key. Give it a name like “workbench key.”\n\nVersion Control:\n\nAdd your files to local version control with git add .\nCommit your files with git commit -m \"my first commit\"\nUsing the https url from github add your github repository as the “remote” with git remote add origin git@github.com:username/repo_name.git\nPush your local files to github with git push -u origin main where main is the name of your branch in github. Type yes to add github to your list of known hosts.\n\nResources\n\nhttps://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent\nhttps://docs.github.com/en/authentication/connecting-to-github-with-ssh/adding-a-new-ssh-key-to-your-github-account?platform=linux\nVim Commands Cheat Sheet\n\n\n\n\n\n\n\n\n\n\nGithub CLI\n\n\n\nTo learn more about the Github CLI and the gh package please check out this article."
  },
  {
    "objectID": "coursework_labs/01_lab_devops_CICD/Deploy_Quarto_GHA.html#part-4-publish-using-gha",
    "href": "coursework_labs/01_lab_devops_CICD/Deploy_Quarto_GHA.html#part-4-publish-using-gha",
    "title": "Lab: Deploy Quarto with GHA",
    "section": "Part 4: Publish using GHA",
    "text": "Part 4: Publish using GHA\n\nWe need to create a gh-pages branch to publish to github pages.\n\ngit status # - make sure everything is committed\ngit checkout --orphan gh-pages\ngit reset --hard # make sure you've committed changes before running this!\ngit commit --allow-empty -m \"Initialising gh-pages branch\"\ngit push origin gh-pages\ngit checkout main\n\nGo to Settings &gt; Pages in your github repository and make sure that your site is being built from the gh-pages branch.\n\n\n\nIn your terminal run quarto publish gh-pages and click Yes to the prompt to update the site.\nYour site should now be live!\nCreate a github action called publish.yaml and save it in .github/workflows:\n\nmkdir .github\ncd .github\nmkdir workflows\ncd workflows\ntouch publish.yaml\n\nEdit the publish.yaml file:\n\nname: Deploy quarto site to Github Pages\n\non:\n  workflow_dispatch:\n  push:\n    branches: ['main']\n\njobs:\n  build-deploy:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: write\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v4\n\n      - name: Set up Quarto\n        uses: quarto-dev/quarto-actions/setup@v2\n\n      - name: Install R\n        uses: r-lib/actions/setup-r@v2\n        with:\n          r-version: '4.2.3'\n          use-public-rspm: true\n\n      - name: Setup renv and install packages\n        uses: r-lib/actions/setup-renv@v2\n        with:\n          cache-version: 1\n        env:\n          RENV_CONFIG_REPOS_OVERRIDE: https://packagemanager.rstudio.com/all/latest\n\n      - name: Render and Publish\n        uses: quarto-dev/quarto-actions/publish@v2\n        with:\n          target: gh-pages\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n\nSnapshot your renv environment with renv::snapshot.\nCommit and push your code: (Make sure that your renv.lock file has been added!)\n\ngit add .\ngit commit -m \"created action\"\ngit push\n\nGo to the actions tab in your Github repository and watch your deploy!"
  },
  {
    "objectID": "coursework_labs/01_lab_devops_CICD/Deploy_Quarto_GHA.html#part-5-publish-to-connect-with-gha",
    "href": "coursework_labs/01_lab_devops_CICD/Deploy_Quarto_GHA.html#part-5-publish-to-connect-with-gha",
    "title": "Lab: Deploy Quarto with GHA",
    "section": "Part 5: Publish to Connect with GHA",
    "text": "Part 5: Publish to Connect with GHA\n\nCreate an API key on the Connect website. Note this API somewhere safe as you will be using it multiple times in the workshop.\n\n\n\nAdd the Connect URL and your API key to your repository:\n\n\nIn your repository go to Settings &gt; Security &gt; Secrets and variables &gt; Actions\nAdd 2 secrets:\n\n\n\nThe rsconnect package needs to be explicitly called in your code to be correctly snapshot in your lock file. Install it and call it in one of your .qmd files.\n\ninstall.packages(\"rsconnect\")\nlibrary(rsconnect)\nrenv::snapshot()\n\nEdit your publish.yaml file:\n\n---\non:\n  workflow_dispatch:\n  push:\n    branches:\n      - main\nname: Quarto and Connect Publish\njobs:\n  build-deploy:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: write\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v4\n      - name: Set up Quarto\n        uses: quarto-dev/quarto-actions/setup@v2\n      - name: Install R\n        uses: r-lib/actions/setup-r@v2\n        with:\n          r-version: 4.2.3\n          use-public-rspm: true\n      - name: Setup renv and install packages\n        uses: r-lib/actions/setup-renv@v2\n        with:\n          cache-version: 1\n        env:\n          RENV_CONFIG_REPOS_OVERRIDE: https://packagemanager.rstudio.com/all/latest\n      - name: Render and Publish\n        uses: quarto-dev/quarto-actions/publish@v2\n        with:\n          target: gh-pages\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n  test-and-connect-publish:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n          \n      - name: Remove `.Rprofile`\n        shell: bash\n        run: |\n          rm .Rprofile\n          \n      - name: Set up Quarto\n        uses: quarto-dev/quarto-actions/setup@v2\n\n      - uses: r-lib/actions/setup-r@v2\n        with:\n          r-version: 4.2.3\n          use-public-rspm: true\n          \n      - uses: r-lib/actions/setup-renv@v2\n      - name: Create manifest.json\n        shell: Rscript {0}\n        run: |\n          rsconnect::writeManifest()\n          \n      - name: Publish Connect content\n        uses: rstudio/actions/connect-publish@main\n        with:\n          url: ${{ secrets.CONNECT_SERVER }}\n          api-key: ${{ secrets.CONNECT_API_KEY }}\n          access-type: logged_in\n          dir: |\n            .:/github-actions"
  },
  {
    "objectID": "coursework_labs/03_lab_data_in_prod/lab_solution.html#setup",
    "href": "coursework_labs/03_lab_data_in_prod/lab_solution.html#setup",
    "title": "Lab: Data in Production",
    "section": "Setup",
    "text": "Setup\nTo setup your cloud-based development environment create an account using your email at http://rstd.io/class with code angry-beaver. Click on the Rstudio Connect widget to start your environment."
  },
  {
    "objectID": "coursework_labs/03_lab_data_in_prod/lab_solution.html#part-1-host-api-on-posit-connect",
    "href": "coursework_labs/03_lab_data_in_prod/lab_solution.html#part-1-host-api-on-posit-connect",
    "title": "Lab: Data in Production",
    "section": "Part 1: Host API on Posit Connect",
    "text": "Part 1: Host API on Posit Connect\n\nGo to the Solutions Engineering R-examples repo and copy the HTTPS url.\nIn Connect click Publish and Import from Git. Enter the URL that you copied above and click Next.\nSelect the main branch and click next.\nSelect the plumber-penguins/app directory and give it a name.\nClick `Deploy Content. In a few moments your API should be live!"
  },
  {
    "objectID": "coursework_labs/03_lab_data_in_prod/lab_solution.html#part-2-explore-your-api",
    "href": "coursework_labs/03_lab_data_in_prod/lab_solution.html#part-2-explore-your-api",
    "title": "Lab: Data in Production",
    "section": "Part 2: Explore your API",
    "text": "Part 2: Explore your API\n\nExplore the endpoints for the API. Click the GET for each endpoint and then click Try it out and Execute.\nClick on the link ending in openapi.json below the title of you API.\n\n\n\nTry accessing the API via the terminal with curl &lt;URL&gt;. You should receive output that the app is not authorized!\nAuthorize the app for everyone by changing the Access &gt; Sharing option to Anyone - no login required and then try the curl command again. It should work now!\n\n\n\nTry out the /penguins endpoint and grab the Request URL.\nAccess the /penguins endpoint and provide input for the sample size in your terminal and in the app itself.\n\ncurl \"&lt;REQUEST URL&gt;/penguins?sample_size=5\""
  },
  {
    "objectID": "coursework_labs/03_lab_data_in_prod/lab_solution.html#part-3-plumber-examples",
    "href": "coursework_labs/03_lab_data_in_prod/lab_solution.html#part-3-plumber-examples",
    "title": "Lab: Data in Production",
    "section": "Part 3: Plumber Examples",
    "text": "Part 3: Plumber Examples\n\nInstall the plumber examples package. remotes::install_github(\"sol-eng/plumberExamples\")\nRun available_apis to see plumber examples in the package.\nAccess examples and code:\n\nlibrary(plumber)\nplumb_api(package = \"plumberExamples\", name = \"00-hello\") %&gt;% pr_run()"
  },
  {
    "objectID": "coursework_labs/03_lab_data_in_prod/lab_solution.html#part-4-push-button-deployment",
    "href": "coursework_labs/03_lab_data_in_prod/lab_solution.html#part-4-push-button-deployment",
    "title": "Lab: Data in Production",
    "section": "Part 4: Push-button deployment",
    "text": "Part 4: Push-button deployment\n\nPublish the 11-car-inventory example to Connect.\nClick the blue publishing icon in the upper right of the file editor.\n\n\n\nWhen prompted connect to the Posit Connect server with the provided url. Click Publish."
  },
  {
    "objectID": "coursework_labs/03_lab_data_in_prod/lab_solution.html#part-5-programmatically-access-connect",
    "href": "coursework_labs/03_lab_data_in_prod/lab_solution.html#part-5-programmatically-access-connect",
    "title": "Lab: Data in Production",
    "section": "Part 5: Programmatically access Connect",
    "text": "Part 5: Programmatically access Connect\n\nWe want to programmatically identify all the content that has been published. You will need to use the Connect API Key that you created in the earlier lab. Or you can create a new key.\n\n\n\nOpen a new R script In your workbench console. Add your Connect information:\n\n# Add server\nrsconnect::addServer(\n  url = \"https://liberal-bullfinch.74633.fleeting.rstd.io/rsconnect/__api__\",\n  name = \"colorado\"\n)\n\n# Add account\nrsconnect::connectApiUser(\n  account = \"\",\n  server = \"colorado\",\n  apiKey = Sys.getenv(\"CONNECT_API_KEY\"),\n)\n\nAccess your content programmatically in R: - need to add key ias env variable\n\nlibrary(httr)\nlibrary(tidyr)\n\n# Use the /v1/content endpoint to retrieve the full list of content items\nresult &lt;- GET(\n  paste0(Sys.getenv(\"CONNECT_SERVER\"),\"__api__/v1/content\"),\n    add_headers(Authorization = paste(\"Key\", Sys.getenv(\"CONNECT_API_KEY\"))))\n\n# Create a tibble for the content list result response\ndf_full &lt;- unnest_wider(tibble::tibble(dat = content(result)), dat) \n\nAccess your content programmatically in the terminal using curl:\n\nexport CONNECT_API_KEY=XXX\nexport CONNECT_SERVER=https://liberal-bullfinch.74633.fleeting.rstd.io/rsconnect/\n\ncurl --silent --show-error -L --max-redirs 0 --fail \\\n    -H \"Authorization: Key ${CONNECT_API_KEY}\" \\\n    \"${CONNECT_SERVER}__api__/v1/content\""
  },
  {
    "objectID": "slides/workshop_full_slides.html#but-firsta-very-brief-history-lesson",
    "href": "slides/workshop_full_slides.html#but-firsta-very-brief-history-lesson",
    "title": "DevOps for Data Scientists",
    "section": "But first…a very brief history lesson",
    "text": "But first…a very brief history lesson\n\n\n\nReason for squishy definition is because it developed organically in the 2007-2009, across social media, twitter tag #devops was popular, online communities and became more organized through conferences, workshops, and grassroots attempts at implementation at diff companies. Then was introduced into larger companies like Intel, PayPal, Facebook.\nBecame more popular through work by Gene Kim and Patrick Debois and others - Pheonix Project is actually a novel about an IT project at a made-up company.\nSo what were all these people trying to do - what was the context? All trying to create something."
  },
  {
    "objectID": "slides/workshop_full_slides.html#so-you-want-to-create-an-app",
    "href": "slides/workshop_full_slides.html#so-you-want-to-create-an-app",
    "title": "DevOps for Data Scientists",
    "section": "So you want to create an app?",
    "text": "So you want to create an app?\n\n\nLet’s talk about what it looks like to create an application. On one side you had developers creating some sort of application - let’s say a stock trading application, so your end user are stock traders\nDevs would work on creating the code for this app, get requirements, test it and then package up all the source code in some way so that its executable and that it could be deployed somehow to those end users you’d configure the server, install any tools and frameworks needed to run the code, and then launch.\nNow your stock traders are using their application - maybe they’re giving feedback somehow or errors are being logged. Another team is monitoring the environment and seeing if servers are able to handle the load of all the users.\nBut eventually you’d need to fix bugs or release new features or maybe change things so that the app could handle more end users -\nyour dev team make updates, version those changes, test them, re-launch the app and you do this over and over again in some sort or release process – so you have this continuous cycle of releasing your app, finding something to fix or add, testing that change, integrating that code, and then releasing the app..\nMaking this continuous process as fast, efficient, accurate, and low risk is the goal of devops.\nsounds pretty efficient right -"
  },
  {
    "objectID": "slides/workshop_full_slides.html#problems-devops-tries-to-solve",
    "href": "slides/workshop_full_slides.html#problems-devops-tries-to-solve",
    "title": "DevOps for Data Scientists",
    "section": "Problems DevOps tries to solve",
    "text": "Problems DevOps tries to solve\n\nSiloed teams\nMiscommunication\nSlow & manual release cycles\nTechnical knowledge siloes\nIncompatible systems or tech stacks\nOpaque undocumented processes\n\n\nUnfortunately this isnt how it started. You want to make the release process as fast as possible but you also want it to be tested and free of bugs. And this introduces a natural conflict between speed and stability\nSo let’s go back to the early aughts. You have the same goals of speed and accuracy - but this process of continuous integration, of testing, of automating processes so that your users can get their hands on the app - didnt exist.\nOne problem is that the entire process is siloed between the creation of the code and the deployment of your app. So your developers finish their code and then throw it over the fence to ops. Maybe they then throw it to security or to QA. But there was no formal alliance in place or processes on how the teams work together. Because each team is seemingly working on one part - the code vs. the deploy - there’s also technical knowledge siloes - each team only knows their bit but not anything else.\nSo imagine this stock trading app - your developers are creating cool new features so that you can easily buy and sell stock, maybe even see data on whats happening in the market. But they’re not necessarily thinking about how the app is secured or if its compliant with federal regulations or if user data is protected. Obvi this is a worst case scenario - but you get the picture.\nSo as the app is built it keeps getting thrown back and forth between the two teams and leads to one of the major problems that devops is trying to fix - really slow and manual bureaucratic release process.\nOn the technical side, a lot of the actual work is done manually. So you can imagine one team running tests manually in one environment - maybe the environment itself is created manually, or someone manually sizing up or fixing a server. This takes time, you need to get approval from people, and its not easily reproduced or really documented anywhere. Also, there is a lot of room for error and if things break its not easy to roll back bugs.\nProblem becomes how do you automate this release process, make it streamlined, less error prone, improve how all these teams integrate and operate, and at the end of the day make the process of getting the app into the hands of your users much faster."
  },
  {
    "objectID": "slides/workshop_full_slides.html#common-devops-principles",
    "href": "slides/workshop_full_slides.html#common-devops-principles",
    "title": "DevOps for Data Scientists",
    "section": "Common DevOps Principles",
    "text": "Common DevOps Principles\n\nCollaboration\nContinuous Integration & Delivery\nAutomation\nReproducibility\nCulture change\n\n\nAs the field of devops developed, there are different implementations/diff technologies of what devops means - these happen differently at different companies But there have been some common philosophies and best practices that have come out that I’ve seen consistently across the entire ecosystem.\nFirst - everyone that’s involved in the creation of this application should be collaborating and working together. This is my wink wink moment for you all of why devops is so important for data scientists\nThen we have this concept of Continuous Integration & Delivery - we’ll take about this in greater length in a few minutes - but this is the process of 1. the coding of the app 2. the versioning of that code is some kind of repository 3. testing those changes 4. integrating them into the app if those tests are passed 5. And then that continuous process of releasing those changes into production\nSo for the CI/CD process to work and specifically to work quickly - we will need some level of automation as we move through that cyclical process. You don’t want to have to pause things to get approval or manually change things when tests pass - you want it to get to the user as quickly as possible after everything has been tested.\nThe next piece is reproducibility. You have different teams working on different pieces of the puzzle, but at the end of the day the end result is the same. Everyone is working on that same app - in this case our stock platform. So as jobs go from one team to another team and as your app goes from development to testing to finally your users, you want to make sure that there’s a common ecoystem that everyone is working in. When you’re testing your app you want to make sure that your environment is as similar to what is going to be in real-life or what is called “production”. You also want to make sure that your code itself is reproducible and that it works for users regardless of their location or their computer or their browser maybe.\nThe last piece that I find really interesting is the concept of culture change. So what needs to change in your organization so that you’re able to function while still holding this tension or conflict between speed and stability. How do you make sure that teams that have different incentives - for example security team vs. a data team - are able to work together.\nSo let me pause - that’s a lot - everyone got a bit of a history lesson but as far as i’m aware no one here is a software developer or an IT engineer. So that brings me to this very important question: But"
  },
  {
    "objectID": "slides/workshop_full_slides.html#why-should-we-as-data-scientists-care-about-this",
    "href": "slides/workshop_full_slides.html#why-should-we-as-data-scientists-care-about-this",
    "title": "DevOps for Data Scientists",
    "section": "Why should we as data scientists care about this?",
    "text": "Why should we as data scientists care about this?\n\\&lt;/iframe\\&gt;\n&lt;aside class=\"notes\"&gt;\n&lt;p&gt;lets have a little thought experiment&lt;/p&gt;\n&lt;/aside&gt;\n&lt;/section&gt;\n&lt;section id=\"has-this-ever-happened-to-you\" class=\"slide level2\"&gt;\n&lt;h2&gt;Has this ever happened to you?&lt;/h2&gt;\n&lt;div class=\"columns\"&gt;\n&lt;div class=\"column\" style=\"width:50%;\"&gt;\n&lt;p&gt;&lt;span class=\"fragment\" data-fragment-index=\"1\"&gt;You come back to code from a year ago and now it doesnt run!&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;div class=\"column\" style=\"width:50%;\"&gt;\n&lt;p&gt;&lt;span class=\"fragment\" data-fragment-index=\"2\" style=\"color: blue;\"&gt;Reproducibility&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;div class=\"columns\"&gt;\n&lt;div class=\"column\" style=\"width:50%;\"&gt;\n&lt;p&gt;&lt;span class=\"fragment\" data-fragment-index=\"3\"&gt;You need to hand off your model to the Engineering team but they only code in Java&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;div class=\"column\" style=\"width:50%;\"&gt;\n&lt;p&gt;&lt;span class=\"fragment\" data-fragment-index=\"4\" style=\"color: blue;\"&gt;Continuous Integration &amp; Delivery &amp; Collaboration&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;div class=\"columns\"&gt;\n&lt;div class=\"column\" style=\"width:50%;\"&gt;\n&lt;p&gt;&lt;span class=\"fragment\" data-fragment-index=\"5\"&gt;Your boss asks you to share that Shiny app with a client but the ops team is too busy working on their roadmap to help you deploy it somewhere.&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;div class=\"column\" style=\"width:50%;\"&gt;\n&lt;p&gt;&lt;span class=\"fragment\" data-fragment-index=\"6\" style=\"color: blue;\"&gt;Culture Change&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/section&gt;\n&lt;section id=\"why-should-data-scientistsanalysts-care-about-devops\" class=\"slide level2\"&gt;\n&lt;h2&gt;Why should data scientists/analysts care about DevOps?&lt;/h2&gt;\n&lt;div&gt;\n&lt;ul&gt;\n&lt;li class=\"fragment\"&gt;&lt;p&gt;Data scientists are developers!&lt;/p&gt;&lt;/li&gt;\n&lt;li class=\"fragment\"&gt;&lt;p&gt;Data science careers have moved from academic sphere to tech and software but education hasnt always followed&lt;/p&gt;&lt;/li&gt;\n&lt;li class=\"fragment\"&gt;&lt;p&gt;Automation, collaboration, testing can dramatically improve data work and improve reproducibility&lt;/p&gt;&lt;/li&gt;\n&lt;li class=\"fragment\"&gt;&lt;p&gt;The many hats of a data scientist&lt;/p&gt;&lt;/li&gt;\n&lt;li class=\"fragment\"&gt;&lt;p&gt;Improve collaboration &amp; communication with other teams&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;\n&lt;aside class=\"notes\"&gt;\n&lt;p&gt;spent a lot of time talking about teams working together to create a shared product. Data scientists are a part of that team. DS is a relatively new field and creating data-intensive apps is a huge part of tech world today.&lt;/p&gt;\n&lt;p&gt;DS career paths started in academia - not a lot of best practices are taught&lt;/p&gt;\n&lt;/aside&gt;\n&lt;/section&gt;\n&lt;section id=\"responsibility-of-the-analyst\" class=\"slide level2\"&gt;\n&lt;h2&gt;Responsibility of the analyst&lt;/h2&gt;\n&lt;div class=\"columns\"&gt;\n&lt;div class=\"column\" style=\"width:50%;\"&gt;\n&lt;p&gt;&lt;img data-src=\"images/Screenshot%202023-08-22%20at%203.26.22%20PM.png\" /&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;div class=\"column\" style=\"width:50%;\"&gt;\n&lt;p&gt;&lt;img data-src=\"images/Screenshot%202023-09-10%20at%2012.18.42%20PM.png\" /&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;aside class=\"notes\"&gt;\n&lt;p&gt;I mentioned before that a lot of DS comes from academia and research. So the concept of reproducing your results - especially if those results play a role in how medicines or medical devices are developed - is incredibly important.&lt;/p&gt;\n&lt;p&gt;2005 essay by John Ioannidis in scientific journal on what is known as the replicability crisis in scientific publishing, arguing that majority medical research studies cannot be replicated.&lt;/p&gt;\n&lt;p&gt;So as data scientists and we are curators of the data and are responsible for its legitimacy in many ways - obv cant always control it of course.&lt;/p&gt;\n&lt;p&gt;This second paper started looking a method of reproducing results - namely Jupyter notebooks - and found a lot of ways that reproducibility was improved but also a lot of places where things could have been done better and some best practices for how to do that - in what we call literate programming.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;27,271&lt;/strong&gt; Notebooks:&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;11,454&lt;/strong&gt; could not declare dependencies&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;5,429&lt;/strong&gt; could not successfully install declared dependencies&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;9,185&lt;/strong&gt; returned an error when ran&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;324&lt;/strong&gt; returned a different result than originally reported&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/aside&gt;\n&lt;/section&gt;\n&lt;section id=\"from-principles-to-tools\" class=\"slide level2\"&gt;\n&lt;h2&gt;From principles to tools&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;CI/CD&lt;/li&gt;\n&lt;li&gt;Environment Management&lt;/li&gt;\n&lt;li&gt;Package Management&lt;/li&gt;\n&lt;li&gt;Version Control &amp; Git workflows&lt;/li&gt;\n&lt;li&gt;Automation Build tools\n&lt;ul&gt;\n&lt;li&gt;YAML&lt;/li&gt;\n&lt;li&gt;Dedicated cloud &amp; CI/CD platforms&lt;/li&gt;\n&lt;li&gt;Infrastructure as Code&lt;/li&gt;\n&lt;li&gt;&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Continuous Monitoring and testing&lt;/li&gt;\n&lt;/ul&gt;\n&lt;aside class=\"notes\"&gt;\n&lt;p&gt;build tools for automating workflows, creating configurations for those workflows, and tools to reproduce environments consistently across workflows&lt;/p&gt;\n&lt;p&gt;discuss these very very briefly&lt;/p&gt;\n&lt;/aside&gt;\n&lt;/section&gt;\n&lt;section id=\"the-cicd-pipeline\" class=\"slide level2\"&gt;\n&lt;h2&gt;The CI/CD Pipeline&lt;/h2&gt;\n&lt;p&gt;&lt;img data-src=\"images/cicd.png\" /&gt;&lt;/p&gt;\n&lt;aside class=\"notes\"&gt;\n&lt;ul&gt;\n&lt;li&gt;an iterative cycle of small steps to quickly build, test, and deploy your code -CI/CD is a critical component tof making DevOps happen. -CI/CD comprises of an iterative cycle continuous integration and continuous delivery or continuous deployment. -Put together, they form a “CI/CD pipeline”—a series of automated workflows that help DevOps teams cut down on manual tasks:&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;-Continuous integration (CI) automatically builds, tests, and commit code changes into a shared repository; Developer writes code and commits to a repo like github. This triggers an automatic process where the code is built, tested and then either passes or fails.&lt;/p&gt;\n&lt;p&gt;-Continuous delivery (CD) delivers code changes to production-ready environments for approval; final step is sometimes manual&lt;/p&gt;\n&lt;p&gt;-Continuous deployment (CD) automatically deploys code changes to customers directly. All code based - not manual&lt;/p&gt;\n&lt;/aside&gt;\n&lt;/section&gt;\n&lt;section id=\"environment-management\" class=\"slide level2 smaller\"&gt;\n&lt;h2 class=\"smaller\"&gt;Environment Management&lt;/h2&gt;\n&lt;aside class=\"notes\"&gt;\n&lt;p&gt;Content is deployed (and code is promoted) across different environments with different intended audiences.&lt;/p&gt;\n&lt;/aside&gt;\n&lt;table style=\"width:99%;\"&gt;\n&lt;colgroup&gt;\n&lt;col style=\"width: 39%\" /&gt;\n&lt;col style=\"width: 41%\" /&gt;\n&lt;col style=\"width: 18%\" /&gt;\n&lt;/colgroup&gt;\n&lt;thead&gt;\n&lt;tr class=\"header\"&gt;\n&lt;th&gt;Dev&lt;/th&gt;\n&lt;th&gt;Test&lt;/th&gt;\n&lt;th&gt;Prod&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr class=\"odd\"&gt;\n&lt;td&gt;&lt;p&gt;a place for data scientists to do exploratory analysis and experiment&lt;/p&gt;\n&lt;p&gt;often just your local desktop&lt;/p&gt;\n&lt;p&gt;data science “sandbox” with data that’s as close to real as possible&lt;/p&gt;\n&lt;p&gt;access to R/Python packages&lt;/p&gt;&lt;/td&gt;\n&lt;td&gt;&lt;p&gt;as similar to prod as possible&lt;/p&gt;\n&lt;p&gt;code testing&lt;/p&gt;\n&lt;p&gt;data validation&lt;/p&gt;\n&lt;p&gt;in software dev world includes integration, unit, and regression testing&lt;/p&gt;&lt;/td&gt;\n&lt;td&gt;&lt;p&gt;separate from dev and test&lt;/p&gt;\n&lt;p&gt;created using code&lt;/p&gt;\n&lt;p&gt;code promotion process + tests&lt;/p&gt;\n&lt;p&gt;completely automatic&lt;/p&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;/section&gt;\n&lt;section id=\"version-control-workflows\" class=\"slide level2\"&gt;\n&lt;h2&gt;Version Control &amp; Workflows&lt;/h2&gt;\n&lt;p&gt;&lt;img data-src=\"images/Screenshot%202023-08-23%20at%2011.20.04%20AM.png\" /&gt;&lt;/p&gt;\n&lt;aside class=\"notes\"&gt;\n&lt;p&gt;Version control is a main tool for Continuous Integration -&lt;/p&gt;\n&lt;p&gt;lots of variants - giit, github., svn, gitlab, etc&lt;/p&gt;\n&lt;p&gt;distributed version control - everyone has their own repo&lt;/p&gt;\n&lt;p&gt;can track changes and roll them back&lt;/p&gt;\n&lt;p&gt;can fix merge conflicts&lt;/p&gt;\n&lt;p&gt;an an iterative process to build, test, collaborate on your code to above environments. Very commonly, individuals work on separate branches that are then tested and reviewed by colleagues before they are merged into a main branch.&lt;/p&gt;\n&lt;p&gt;In addition to the action of promoting your code - its also important to have processes in place for how it happens code reviews, process for your team, how to name things, pull requests, version control with git, feature branching, automatic tests&lt;/p&gt;\n&lt;/aside&gt;\n&lt;/section&gt;\n&lt;section id=\"lab-activity\" class=\"slide level2\"&gt;\n&lt;h2&gt;Lab Activity&lt;/h2&gt;\n&lt;p&gt;🟥 - I need help&lt;/p&gt;\n&lt;p&gt;🟨 - I’m still working&lt;/p&gt;\n&lt;p&gt;🟩 - I’m done&lt;/p&gt;\n&lt;p&gt;Login to pos.it/class with code &lt;code&gt;conftest&lt;/code&gt; and create an account with your name and email&lt;/p&gt;\n&lt;p&gt;Complete Part 1 of Lab - add link&lt;/p&gt;\n&lt;/section&gt;\n&lt;section id=\"reproducing-your-environment\" class=\"slide level2\"&gt;\n&lt;h2&gt;Reproducing your environment&lt;/h2&gt;\n&lt;p&gt;What are the layers that need to be reproduced across your dev, test, and prod environments?&lt;/p&gt;\n&lt;p&gt;In your day-to-day work, what’s the hardest reproducibility challenge?&lt;/p&gt;\n&lt;/section&gt;\n&lt;section id=\"layers-of-reproducibility\" class=\"slide level2\"&gt;\n&lt;h2&gt;Layers of reproducibility&lt;/h2&gt;\n&lt;table style=\"width:69%;\"&gt;\n&lt;colgroup&gt;\n&lt;col style=\"width: 22%\" /&gt;\n&lt;col style=\"width: 47%\" /&gt;\n&lt;/colgroup&gt;\n&lt;thead&gt;\n&lt;tr class=\"header\"&gt;\n&lt;th&gt;Layer&lt;/th&gt;\n&lt;th&gt;Contents&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr class=\"odd\"&gt;\n&lt;td&gt;Code&lt;/td&gt;\n&lt;td&gt;scripts, configs, applications&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr class=\"even\"&gt;\n&lt;td&gt;Packages&lt;/td&gt;\n&lt;td&gt;R + Python Packages&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr class=\"odd\"&gt;\n&lt;td&gt;System&lt;/td&gt;\n&lt;td&gt;&lt;p&gt;R + Python Language Versions&lt;/p&gt;\n&lt;p&gt;System Libraries&lt;/p&gt;\n&lt;p&gt;Operating System + dependencies&lt;/p&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr class=\"even\"&gt;\n&lt;td&gt;Hardware&lt;/td&gt;\n&lt;td&gt;&lt;p&gt;Virtual Hardware&lt;/p&gt;\n&lt;p&gt;Physical Hardware&lt;/p&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;aside class=\"notes\"&gt;\n&lt;ul&gt;\n&lt;li&gt;Let’s say someone wanted to reproduce your project including your code and your environment. Make a list of the layers that would need to be reproduced on their machine. (For example, a layer would be the version of R that you’re using)&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;options(“repos”) Run .libPaths()&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Hints:&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;Inspect your renv.lock file.&lt;/li&gt;\n&lt;li&gt;Where are your packages being pulled from? Confirm by typing &lt;code&gt;options(\"repos\")&lt;/code&gt;.\n&lt;ul&gt;\n&lt;li&gt;You can modify your package repository by running &lt;code&gt;options(\"repos\" = c(\"&lt;REPO-NAME&gt;\" = \"https://your-repository-url.com\"))&lt;/code&gt; in your RStudio console.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Visit the webpage where packages are being pulled from and see if you can identify package dependencies. Are packages downloaded as binaries or from source?&lt;/li&gt;\n&lt;li&gt;What are your server and OS dependencies? (If you are not sure which distribution of Linux you are using, you can find it by typing &lt;code&gt;cat /etc/*-release&lt;/code&gt; in your terminal)&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/aside&gt;\n&lt;/section&gt;\n&lt;section id=\"mechanisms-for-reproducibility\" class=\"slide level2\"&gt;\n&lt;h2&gt;Mechanisms for reproducibility&lt;/h2&gt;\n&lt;p&gt;** make this a diagram starting from least to most reproducibility&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;documenting state &amp; version control&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;virtual environments (&lt;code&gt;renv&lt;/code&gt;, &lt;code&gt;venv&lt;/code&gt;) + package management&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Containerization &amp; docker&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Infrastructure as Code&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/section&gt;\n&lt;section id=\"packages-vs.-libraries-vs.-repositories\" class=\"slide level2\"&gt;\n&lt;h2&gt;Packages vs. Libraries vs. Repositories&lt;/h2&gt;\n&lt;p&gt;&lt;strong&gt;Package&lt;/strong&gt; - contains code, functions, data, and documentation.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Library&lt;/strong&gt; - is a directory where packages are installed.&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Repository&lt;/strong&gt; - a collection of packages. CRAN is a public external repository that is a network of servers that distribute R along with R packages.&lt;/p&gt;\n&lt;aside class=\"notes\"&gt;\n&lt;p&gt;packages - Can be be distributed as SOURCE (a directory with all package components), &lt;a href=\"https://solutions.posit.co/envs-pkgs/environments/repositories/index.html#binary-packages\"&gt;BINARIES&lt;/a&gt; (contains files in OS-specific format) or as a BUNDLE (compressed file containing package components, similar to source).&lt;/p&gt;\n&lt;p&gt;library - You can have user-level or project-level libraries. Run &lt;code&gt;.libPaths()&lt;/code&gt; to see yours. To use a package in has to be installed in a library with &lt;code&gt;install.packages()&lt;/code&gt; and then loaded into memory with &lt;code&gt;library(x)&lt;/code&gt; .&lt;/p&gt;\n&lt;p&gt;repo - others include pypi, bioconducter, private repos&lt;/p&gt;\n&lt;/aside&gt;\n&lt;/section&gt;\n&lt;section id=\"renv-workflow\" class=\"slide level2\"&gt;\n&lt;h2&gt;Renv workflow&lt;/h2&gt;\n&lt;p&gt;&lt;img data-src=\"images/Screenshot%202023-09-06%20at%208.31.22%20PM.png\" /&gt;&lt;/p&gt;\n&lt;aside class=\"notes\"&gt;\n&lt;ol type=\"1\"&gt;\n&lt;li&gt;&lt;p&gt;Use a version control system e.g.&lt;a href=\"https://git-scm.com/\"&gt;git&lt;/a&gt; with &lt;a href=\"https://github.com/\"&gt;GitHub&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;One user (perhaps yourself) should explicitly initialize &lt;code&gt;renv&lt;/code&gt; in the project, via &lt;a href=\"https://rstudio.github.io/renv/reference/init.html\"&gt;&lt;code&gt;renv::init()&lt;/code&gt;&lt;/a&gt;. This will create the initial &lt;code&gt;renv&lt;/code&gt; lockfile, and also write the &lt;code&gt;renv&lt;/code&gt; auto-loaders to the project’s &lt;code&gt;.Rprofile&lt;/code&gt; and &lt;code&gt;renv/activate.R&lt;/code&gt;. These will ensure the right version of &lt;code&gt;renv&lt;/code&gt; is downloaded and installed for your collaborators when they start in this project.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Using a branching strategy push your code alongside the generated lockfile &lt;code&gt;renv.lock&lt;/code&gt;. Be sure to also share the generated auto-loaders in &lt;code&gt;.Rprofile&lt;/code&gt; and &lt;code&gt;renv/activate.R&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;When a collaborator first launches in this project, &lt;code&gt;renv&lt;/code&gt; should automatically bootstrap itself, thereby downloading and installing the appropriate version of &lt;code&gt;renv&lt;/code&gt; into the project library. After this has completed, they can then use &lt;a href=\"https://rstudio.github.io/renv/reference/restore.html\"&gt;&lt;code&gt;renv::restore()&lt;/code&gt;&lt;/a&gt; to restore the project library locally on their machine.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/aside&gt;\n&lt;/section&gt;\n&lt;section id=\"example\" class=\"slide level2\"&gt;\n&lt;h2&gt;Example&lt;/h2&gt;\n&lt;p&gt;&lt;code&gt;{.libpaths()} # install.packages(\"renv\") renv::init() renv::snapshot() lapply(.libPaths(), list.files)&lt;/code&gt;&lt;/p&gt;\n&lt;div class=\"footer\"&gt;\n&lt;p&gt;🔍 Live code&lt;/p&gt;\n&lt;/div&gt;\n&lt;/section&gt;\n&lt;section id=\"lab-activity-1\" class=\"slide level2\"&gt;\n&lt;h2&gt;Lab Activity&lt;/h2&gt;\n&lt;p&gt;🟥 - I need help&lt;/p&gt;\n&lt;p&gt;🟨 - I’m still working&lt;/p&gt;\n&lt;p&gt;🟩 - I’m done&lt;/p&gt;\n&lt;p&gt;Complete Part 2 of Lab: Deploy Quarto with GHA including the exercises&lt;/p&gt;\n&lt;/section&gt;\n&lt;section id=\"build-tools\" class=\"slide level2\"&gt;\n&lt;h2&gt;Build tools&lt;/h2&gt;\n&lt;aside class=\"notes\"&gt;\n&lt;p&gt;tools that automate the process of building and deploying your code once it goes from your dev env to test and prod&lt;/p&gt;\n&lt;p&gt;Tools include config files, &lt;code&gt;config&lt;/code&gt; package, CI/CD software such as GHA, automatic tests&lt;/p&gt;\n&lt;/aside&gt;\n&lt;p&gt;&lt;img data-src=\"images/Screenshot%202023-08-23%20at%202.49.21%20PM.png\" /&gt;&lt;/p&gt;\n&lt;div class=\"footer\"&gt;\n&lt;p&gt;Illustration credit:&lt;/p&gt;\n&lt;/div&gt;\n&lt;/section&gt;\n&lt;section id=\"power-of-yaml\" class=\"slide level2\"&gt;\n&lt;h2&gt;Power of YAML&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;YAML Ain’t Markup Language&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;communication of data between people and computers.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;human friendly&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;everything is a key value pair and interpreted as maps or dictionaries&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;used for configuration files across many execution environments including Docker, virtual machines, K8s, helm, IaaS, etc&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/section&gt;\n&lt;section id=\"xml\" class=\"slide level2\"&gt;\n&lt;h2&gt;XML&lt;/h2&gt;\n&lt;pre&gt;&lt;code&gt;&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;EmpRecord&gt;\n&lt;Employee id=&quot;emp01&quot;&gt;\n&lt;name&gt;Alex&lt;/name&gt;\n&lt;job&gt;Developer&lt;/job&gt;\n&lt;skills&gt;python, C/C++, paskal&lt;/skills&gt;\n&lt;/Employee&gt;\n \n&lt;Employee id=&quot;emp02&quot;&gt;\n&lt;name&gt;Bob&lt;/name&gt;\n&lt;job&gt;Tester&lt;/job&gt;\n&lt;skills&gt;lips, forton, REST APIs&lt;/skills&gt;\n&lt;/Employee&gt;\n \n&lt;/EmpRecord&gt;&lt;/code&gt;&lt;/pre&gt;\n&lt;/section&gt;\n&lt;section id=\"json\" class=\"slide level2\"&gt;\n&lt;h2&gt;JSON&lt;/h2&gt;\n&lt;pre&gt;&lt;code&gt;{\n&quot;EmpRecord&quot;: {\n&quot;Employee&quot;: [\n{\n&quot;-id&quot;: &quot;emp01&quot;,\n&quot;name&quot;: &quot;Alex&quot;,\n&quot;job&quot;: &quot;Developer&quot;,\n&quot;skills&quot;: &quot;python, C/C++, paskal&quot;\n},\n{\n&quot;-id&quot;: &quot;emp02&quot;,\n&quot;name&quot;: &quot;Bob&quot;,\n&quot;job&quot;: &quot;Tester&quot;,\n&quot;skills&quot;: &quot;lips, forton, REST APIs&quot;\n}\n]\n}\n}&lt;/code&gt;&lt;/pre&gt;\n&lt;/section&gt;\n&lt;section id=\"yaml\" class=\"slide level2\"&gt;\n&lt;h2&gt;YAML&lt;/h2&gt;\n&lt;pre&gt;&lt;code&gt;EmpRecord:  \n  emp01:\n    name: Alex\n    job: Developer\n    skills: python, C/C++, paskal\n  emp02:\n    name: Bob\n    job: Tester\n    skills: lips, forton, REST APIs&lt;/code&gt;&lt;/pre&gt;\n&lt;/section&gt;\n&lt;section id=\"yaml-syntax\" class=\"slide level2\"&gt;\n&lt;h2&gt;YAML syntax&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;whitespace indentation is used to denote structure, no need for quotes nor brackets&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Colons separate keys and their values&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Dashes are used to denote a list&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;https://github.com/sd031/yaml-crash-course/blob/main/full_example.yaml&lt;/p&gt;\n&lt;/section&gt;\n&lt;section id=\"examples\" class=\"slide level2\"&gt;\n&lt;h2&gt;Examples&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;https://github.com/rstudio/rstudio-docker-products/blob/dev/docker-compose.yml&lt;/li&gt;\n&lt;li&gt;https://github.com/Rikagx/personal-website/blob/main/.github/workflows/publish.yaml&lt;/li&gt;\n&lt;/ul&gt;\n&lt;div class=\"footer\"&gt;\n&lt;p&gt;🔍 Live code&lt;/p&gt;\n&lt;/div&gt;\n&lt;/section&gt;\n&lt;section id=\"lab-activity-2\" class=\"slide level2\"&gt;\n&lt;h2&gt;Lab Activity&lt;/h2&gt;\n&lt;p&gt;🟥 - I need help&lt;/p&gt;\n&lt;p&gt;🟨 - I’m still working&lt;/p&gt;\n&lt;p&gt;🟩 - I’m done&lt;/p&gt;\n&lt;p&gt;Inspect your _quarto.yml file and identify what each part of it does using the quarto site.&lt;/p&gt;\n&lt;/section&gt;\n&lt;section id=\"is-version-control-secure\" class=\"slide level2\"&gt;\n&lt;h2&gt;Is version control secure?&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;our code is still saved locally&lt;/li&gt;\n&lt;li&gt;How do we make sure that the code we push to Github (or elsewhere) is secure?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/section&gt;\n&lt;section id=\"a-short-auth-teaser\" class=\"slide level2\"&gt;\n&lt;h2&gt;A short auth teaser&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;We can use a variety of data sharing “transfer protocols”&lt;/li&gt;\n&lt;li&gt;protocols specify what kind of traffic is moving between 2 machines&lt;/li&gt;\n&lt;li&gt;a port specifies where to direct the traffic&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;img data-src=\"images/Screenshot%202023-09-07%20at%209.28.32%20AM.png\" /&gt;&lt;/p&gt;\n&lt;aside class=\"notes\"&gt;\n&lt;p&gt;whether its email, text, files, etc A port is a virtual point where network connections start and end. Ports are software-based and managed by a computer’s operating system. Ports allow computers to easily differentiate between different kinds of traffic: emails go to a different port than webpages, for instance, even though both reach a computer over the same Internet connection.&lt;/p&gt;\n&lt;/aside&gt;\n&lt;/section&gt;\n&lt;section id=\"git-protocol-options\" class=\"slide level2\"&gt;\n&lt;h2&gt;Git protocol options&lt;/h2&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr class=\"header\"&gt;\n&lt;th&gt;http&lt;/th&gt;\n&lt;th&gt;https&lt;/th&gt;\n&lt;th&gt;SSH&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr class=\"odd\"&gt;\n&lt;td&gt;port 80&lt;/td&gt;\n&lt;td&gt;port 443&lt;/td&gt;\n&lt;td&gt;port 22&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;p&gt;http - text sent over the internet&lt;/p&gt;\n&lt;p&gt;https - http encrypted with “SSL/TLS”&lt;/p&gt;\n&lt;p&gt;SSH - secure shell&lt;/p&gt;\n&lt;aside class=\"notes\"&gt;\n&lt;p&gt;hypertext transfer protocol When a web user wants to load or interact with a web page, their web browser sends an HTTP request to the origin server that hosts the website’s files. These requests are essentially lines of text that are sent via the internet.&lt;/p&gt;\n&lt;p&gt;https : http encrypted with SSL/TLS - digital certificates that establish an encrypted connected&lt;/p&gt;\n&lt;p&gt;SSH: secure shell, public-key cryptography to authenticate the client, used for remote logins, command line execution&lt;/p&gt;\n&lt;p&gt;HTTPS is simpler. For most services besides Github, you just have to enter in your username and password, and you’ll be able to push and pull code.&lt;/p&gt;\n&lt;p&gt;You don’t have to juggle multiple SSH keys around to use multiple devices.&lt;/p&gt;\n&lt;p&gt;Port 443, which HTTPS uses, is open in basically any firewall that can access the internet. That isn’t always the case for SSH.&lt;/p&gt;\n&lt;p&gt;The primary downside for most people is that you must enter your Git password/token every time you push. While it gets added to a cache, it’s not configured to cache permanently (though this can be changed). With SSH keys, it just uses the key file on disk every time.&lt;/p&gt;\n&lt;p&gt;Where SSH takes the lead is with the authentication factor—the key. The length of it alone makes it harder to accidentally leak, and due to it being unwieldy and unique, it’s generally more secure.&lt;/p&gt;\n&lt;/aside&gt;\n&lt;/section&gt;\n&lt;section id=\"which-one-should-i-use\" class=\"slide level2\"&gt;\n&lt;h2&gt;Which one should I use&lt;/h2&gt;\n&lt;div class=\"columns\"&gt;\n&lt;div class=\"column\" style=\"width:50%;\"&gt;\n&lt;p&gt;https - simpler - username and password or PAT - have to either cache credentials or enter in every time. can be used with Github REST API&lt;/p&gt;\n&lt;/div&gt;&lt;div class=\"column\" style=\"width:50%;\"&gt;\n&lt;p&gt;SSH - potentially more secure - uses key for auth - created per machine once&lt;/p&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/section&gt;\n&lt;section id=\"port-examples\" class=\"slide level2\"&gt;\n&lt;h2&gt;Port Examples&lt;/h2&gt;\n&lt;p&gt;&lt;img data-src=\"images/ports-01.jpg\" /&gt;&lt;/p&gt;\n&lt;aside class=\"notes\"&gt;\n&lt;p&gt;Each port is associated with a specific process or service.&lt;/p&gt;\n&lt;p&gt;show ping localhost&lt;/p&gt;\n&lt;/aside&gt;\n&lt;/section&gt;\n&lt;section id=\"lab-activity-3\" class=\"slide level2\"&gt;\n&lt;h2&gt;Lab Activity&lt;/h2&gt;\n&lt;p&gt;🟥 - I need help&lt;/p&gt;\n&lt;p&gt;🟨 - I’m still working&lt;/p&gt;\n&lt;p&gt;🟩 - I’m done&lt;/p&gt;\n&lt;p&gt;Part 3 of Lab: Deploy Quarto with GHA including the exercises&lt;/p&gt;\n&lt;aside class=\"notes\"&gt;\n&lt;p&gt;show first part&lt;/p&gt;\n&lt;p&gt;git config –list git config –global user.name “Your Name” git config –global user.email “youremail@yourdomain.com”&lt;/p&gt;\n&lt;/aside&gt;\n&lt;/section&gt;\n&lt;section id=\"automation-build-tools\" class=\"slide level2\"&gt;\n&lt;h2&gt;Automation Build Tools&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;GHA is one tool to automate developer workflows&lt;/li&gt;\n&lt;li&gt;CI/CD is just one example of these workflows&lt;/li&gt;\n&lt;li&gt;Runs on github servers&lt;/li&gt;\n&lt;li&gt;Uses yaml&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;img data-src=\"images/Screenshot%202023-09-10%20at%201.32.42%20PM.png\" /&gt;&lt;/p&gt;\n&lt;aside class=\"notes\"&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;A github action allows us to create workflows that are triggered by a github action such as a push or pull to a branch&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Build tools + version control in on system&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Parts of a GHA - trigger, job, steps&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Workflows can include tests, markdown renders, shell scripts, cron jobs, or deployments. They can be as simple or as complicated as you need. Open-source community provides a ton of examples of actions.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Open source collection of “available” actions&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;ol type=\"1\"&gt;\n&lt;li&gt;In the previous exercise we created a repo - we can use it to see what kind of actions we can create&lt;/li&gt;\n&lt;/ol&gt;\n&lt;p&gt;https://github.com/Rikagx/workshop_testing/blob/master/.github/workflows/publish.yaml&lt;/p&gt;\n&lt;p&gt;github.com/actions&lt;/p&gt;\n&lt;p&gt;https://github.com/r-lib/actions&lt;/p&gt;\n&lt;/aside&gt;\n&lt;/section&gt;\n&lt;section id=\"actions-ecosystem\" class=\"slide level2\"&gt;\n&lt;h2&gt;Actions Ecosystem&lt;/h2&gt;\n&lt;p&gt;github.com/actions&lt;/p&gt;\n&lt;p&gt;github.com/r-lib/actions&lt;/p&gt;\n&lt;p&gt;https://github.com/Rikagx/ssh_testing/actions/new&lt;/p&gt;\n&lt;/section&gt;\n&lt;section id=\"syntax\" class=\"slide level2 smaller\"&gt;\n&lt;h2 class=\"smaller\"&gt;Syntax&lt;/h2&gt;\n&lt;pre&gt;&lt;code&gt;name: My Workflow\non:\n  push:\n    branches:\n      - releases\nenv:\n  my_token: ${{ secrets.GITHUB_TOKEN }}\njobs:\n  job_1:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checking out our code\n        uses: actions/checkout@master\n      - name: Say something\n        run: |\n          echo &quot;A little less ${message}&quot;\n          echo &quot;A little more action&quot;\n  job_2:\n    needs: job_1\n    container:\n      image: node:10.16\n      env:\n        NODE_ENV: development\n      ports:\n        - 80\n      volumes:\n        - my_docker_volume:/volume_mount\n      options: --cpus 1&lt;/code&gt;&lt;/pre&gt;\n&lt;/section&gt;\n&lt;section id=\"lab-activity-4\" class=\"slide level2\"&gt;\n&lt;h2&gt;Lab Activity&lt;/h2&gt;\n&lt;p&gt;🟥 - I need help&lt;/p&gt;\n&lt;p&gt;🟨 - I’m still working&lt;/p&gt;\n&lt;p&gt;🟩 - I’m done&lt;/p&gt;\n&lt;p&gt;Part 4 of Lab: Deploy Quarto with GHA including the exercises&lt;/p&gt;\n&lt;/section&gt;\n&lt;section id=\"part-3-goals-docker-for-data-scientists\" class=\"slide level2\"&gt;\n&lt;h2&gt;Part 3 Goals: Docker for Data Scientists&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;to understand different docker workflows&lt;/li&gt;\n&lt;li&gt;to learn common docker syntax for building and running containers&lt;/li&gt;\n&lt;li&gt;to get hands on experience building and running containers&lt;/li&gt;\n&lt;li&gt;to explore the linux file system&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/section&gt;\n&lt;section id=\"introduction-to-docker\" class=\"slide level2\"&gt;\n&lt;h2&gt;Introduction to Docker&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;Open-source tool.&lt;/li&gt;\n&lt;li&gt;Package applications and its dependencies in a unit called a container.&lt;/li&gt;\n&lt;li&gt;Create isolated environments for different experiments.&lt;/li&gt;\n&lt;li&gt;Share work with colleagues without environment setup issues.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;aside class=\"notes\"&gt;\n&lt;p&gt;Docker is a tool that allows you to virtualize (put your computer in the cloud) everything you need to create an application or in this case a data science product You can share containers with colleagues without requiring them to have to set up their own local machines Without something like this, in order to recreate or test code that someone else wrote, you’d need every developer to download the same dependencies, configurations, scripts and make sure that it ran on their machine - whether thats a mac, or windows, or linux or some other operating system&lt;/p&gt;\n&lt;/aside&gt;\n&lt;/section&gt;\n&lt;section id=\"lifecycle\" class=\"slide level2\"&gt;\n&lt;h2&gt;Lifecycle&lt;/h2&gt;\n&lt;p&gt;Dockerfile - script of instruction to build an image&lt;/p&gt;\n&lt;p&gt;Image - read-only instructions that build everything you need to run an application. Made up of layers&lt;/p&gt;\n&lt;p&gt;Container - isolated instance of a running image&lt;/p&gt;\n&lt;p&gt;Image Registry - repository for images&lt;/p&gt;\n&lt;p&gt;&lt;img data-src=\"images/lifecycle.png\" /&gt;&lt;/p&gt;\n&lt;div class=\"footer\"&gt;\n&lt;p&gt;Illustration credit: Alex Gold, do4ds.com&lt;/p&gt;\n&lt;/div&gt;\n&lt;/section&gt;\n&lt;section id=\"how-do-data-scientists-use-docker\" class=\"slide level2\"&gt;\n&lt;h2&gt;How do data scientists use docker?&lt;/h2&gt;\n&lt;/section&gt;\n&lt;section id=\"docker-as-testing-environment\" class=\"slide level2\"&gt;\n&lt;h2&gt;Docker as testing environment&lt;/h2&gt;\n&lt;p&gt;&lt;img data-src=\"images/Screenshot%202023-09-12%20at%209.49.46%20AM.png\" /&gt;&lt;/p&gt;\n&lt;/section&gt;\n&lt;section id=\"example-1\" class=\"slide level2\"&gt;\n&lt;h2&gt;Example&lt;/h2&gt;\n&lt;div class=\"sourceCode\" id=\"cb5\"&gt;&lt;pre class=\"sourceCode numberSource bash number-lines\"&gt;&lt;code class=\"sourceCode bash\"&gt;&lt;span id=\"cb5-1\"&gt;&lt;a href=\"#cb5-1\"&gt;&lt;/a&gt;&lt;span class=\"ex\"&gt;docker&lt;/span&gt; pull postgres:12&lt;/span&gt;\n&lt;span id=\"cb5-2\"&gt;&lt;a href=\"#cb5-2\"&gt;&lt;/a&gt;&lt;span class=\"ex\"&gt;docker&lt;/span&gt; pull postgres:latest&lt;/span&gt;\n&lt;span id=\"cb5-3\"&gt;&lt;a href=\"#cb5-3\"&gt;&lt;/a&gt;&lt;span class=\"ex\"&gt;docker&lt;/span&gt; container ls &lt;span class=\"at\"&gt;-a&lt;/span&gt;&lt;/span&gt;\n&lt;span id=\"cb5-4\"&gt;&lt;a href=\"#cb5-4\"&gt;&lt;/a&gt;&lt;span class=\"ex\"&gt;docker&lt;/span&gt; run &lt;span class=\"at\"&gt;-d&lt;/span&gt; &lt;span class=\"at\"&gt;-e&lt;/span&gt; POSTGRES_PASSWORD=mysecretpassword &lt;span class=\"at\"&gt;--name&lt;/span&gt; postgres_early imageID&lt;/span&gt;\n&lt;span id=\"cb5-5\"&gt;&lt;a href=\"#cb5-5\"&gt;&lt;/a&gt;&lt;span class=\"ex\"&gt;docker&lt;/span&gt; run &lt;span class=\"at\"&gt;-d&lt;/span&gt; &lt;span class=\"at\"&gt;-e&lt;/span&gt; POSTGRES_PASSWORD=mysecretpassword &lt;span class=\"at\"&gt;--name&lt;/span&gt; postgres_new imageID&lt;/span&gt;\n&lt;span id=\"cb5-6\"&gt;&lt;a href=\"#cb5-6\"&gt;&lt;/a&gt;&lt;span class=\"ex\"&gt;docker&lt;/span&gt; container ls &lt;span class=\"at\"&gt;-a&lt;/span&gt;&lt;/span&gt;\n&lt;span id=\"cb5-7\"&gt;&lt;a href=\"#cb5-7\"&gt;&lt;/a&gt;&lt;span class=\"ex\"&gt;docker&lt;/span&gt; stop&lt;/span&gt;\n&lt;span id=\"cb5-8\"&gt;&lt;a href=\"#cb5-8\"&gt;&lt;/a&gt;&lt;span class=\"ex\"&gt;docker&lt;/span&gt; restart&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;\n&lt;div class=\"footer\"&gt;\n&lt;p&gt;🔍 Live code&lt;/p&gt;\n&lt;/div&gt;\n&lt;aside class=\"notes\"&gt;\n&lt;p&gt;a dockerfile is the recipe to build a docker images this recipe is stored in some sort of repository, this can be private, public, or dockerhub - which is the default a docker image contains lightweight instructions to create your application. Docker images use something called layers which makes it super easy and quick to update. Layers start at a base layer which is usually the linux operating system and then they go up to the application layer. a container is the environment for a running process of an image - so if an image is running then its using a container instance. You can have multiple containers running at the same time. But once you delete it everything inside of it goes away.&lt;/p&gt;\n&lt;p&gt;Let’s see an example of what this looks like in practice. Lets say we need to use a postgres sql database for some testing - but we want to test using an older and a newer version of postgres.&lt;/p&gt;\n&lt;p&gt;Lets go to Dockerhub and search for it. We can see official images but there are also thousands of them created by people- hub only has images not dockerfiles or containers themselves. docker image ls - lets list all the images that we have docker pull postgres:12 - see how its pulling and extracting all these layers - but what if we want a newer version or what if we need to run both versions on our machine&lt;/p&gt;\n&lt;p&gt;docker pull postgres:latest - notice how some of these layers already exist so it takes a lot less time&lt;/p&gt;\n&lt;p&gt;Lets go on dockerhub and see if we can understand a bit more about the layers https://hub.docker.com/layers/library/postgres/12/images/sha256-a97fd76ab09599e2ddc15c90a87f9a4a2a60551d99f8e7397f12a1d606d7f0ab?context=explore -&lt;/p&gt;\n&lt;p&gt;we can see that there are a lot of layers but its hard to understand what exactly is happening - lets look at the dockerfile that shows us the recipe for postgres - this is usually saved in a &lt;a href=\"https://github.com/docker-library/docs/blob/master/postgres/README.md\"&gt;github&lt;/a&gt; repo - not on dockerhub which is just images&lt;/p&gt;\n&lt;p&gt;every docker file starts with a from command - this is the base layers that starts the image, then we are running some things, copying , env variables, and starting&lt;/p&gt;\n&lt;p&gt;lets run the image and see&lt;/p&gt;\n&lt;/aside&gt;\n&lt;/section&gt;\n&lt;section id=\"docker-as-development-environment\" class=\"slide level2\"&gt;\n&lt;h2&gt;Docker as development environment&lt;/h2&gt;\n&lt;p&gt;&lt;img data-src=\"images/Screenshot%202023-09-12%20at%2010.00.41%20AM.png\" /&gt;&lt;/p&gt;\n&lt;/section&gt;\n&lt;section id=\"example-2\" class=\"slide level2\"&gt;\n&lt;h2&gt;Example&lt;/h2&gt;\n&lt;pre&gt;&lt;code&gt;# pull the image\ndocker pull rocker/rstudio:4.2.2\n\n# run container\ndocker run --rm \\\n           -p 8888:8787 \\\n           -e PASSWORD=password \\\n           rocker/rstudio:4.2.2&lt;/code&gt;&lt;/pre&gt;\n&lt;/section&gt;\n&lt;section id=\"docker-as-a-portable-app-in-production\" class=\"slide level2\"&gt;\n&lt;h2&gt;Docker as a portable app (in production)&lt;/h2&gt;\n&lt;p&gt;&lt;img data-src=\"images/shiny.png\" width=\"74\" /&gt;&lt;/p&gt;\n&lt;p&gt;&lt;img data-src=\"images/plumber.png\" width=\"74\" /&gt;&lt;/p&gt;\n&lt;p&gt;&lt;img data-src=\"images/bookdown.png\" width=\"74\" /&gt;&lt;/p&gt;\n&lt;p&gt;&lt;img data-src=\"images/tidymodels.png\" width=\"74\" /&gt;&lt;/p&gt;\n&lt;/section&gt;\n&lt;section id=\"example-3\" class=\"slide level2\"&gt;\n&lt;h2&gt;Example&lt;/h2&gt;\n&lt;p&gt;&lt;img data-src=\"images/Screenshot%202023-09-12%20at%2010.14.39%20AM.png\" /&gt;&lt;/p&gt;\n&lt;/section&gt;\n&lt;section id=\"docker-for-cicd\" class=\"slide level2\"&gt;\n&lt;h2&gt;Docker for CI/CD&lt;/h2&gt;\n&lt;p&gt;&lt;img data-src=\"images/docker_ci.png\" /&gt;&lt;/p&gt;\n&lt;/section&gt;\n&lt;section id=\"example-4\" class=\"slide level2\"&gt;\n&lt;h2&gt;Example&lt;/h2&gt;\n&lt;pre&gt;&lt;code&gt;jobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      -\n        name: Checkout\n        uses: actions/checkout@v3\n      -\n        name: Login to Docker Hub\n        uses: docker/login-action@v2\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n      -\n        name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v2\n      -\n        name: Build and push\n        uses: docker/build-push-action@v4\n        with:\n          context: .\n          file: ./Dockerfile\n          push: true\n          tags: ${{ secrets.DOCKERHUB_USERNAME }}/latest&lt;/code&gt;&lt;/pre&gt;\n&lt;aside class=\"notes\"&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Data scientists benefit from Docker’s consistency and reproducibility.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Create isolated environments for different experiments.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Share work with colleagues without environment setup issues.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Consistency:&lt;/strong&gt; Containers ensure that applications run the same way across different environments.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Isolation:&lt;/strong&gt; Containers isolate applications and their dependencies, preventing conflicts.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Portability:&lt;/strong&gt; Containers can run on any system that supports Docker, reducing “it works on my machine” issues.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/aside&gt;\n&lt;/section&gt;\n&lt;section id=\"docker-as-a-platform\" class=\"slide level2\"&gt;\n&lt;h2&gt;Docker as a platform&lt;/h2&gt;\n&lt;p&gt;&lt;img data-src=\"images/shiny-01.png\" width=\"100\" /&gt;&lt;/p&gt;\n&lt;p&gt;&lt;img data-src=\"images/rsconnect.png\" width=\"100\" /&gt;&lt;/p&gt;\n&lt;/section&gt;\n&lt;section id=\"example-5\" class=\"slide level2\"&gt;\n&lt;h2&gt;Example&lt;/h2&gt;\n&lt;pre&gt;&lt;code&gt;docker run -d -p 3838:3838 rocker/shiny&lt;/code&gt;&lt;/pre&gt;\n&lt;/section&gt;\n&lt;section id=\"virtual-machine-vs.-container\" class=\"slide level2\"&gt;\n&lt;h2&gt;Virtual Machine vs. Container&lt;/h2&gt;\n&lt;p&gt;&lt;img data-src=\"images/Screenshot%202023-09-03%20at%209.56.54%20AM.png\" /&gt;&lt;/p&gt;\n&lt;aside class=\"notes\"&gt;\n&lt;p&gt;containers are very lightweight which makes it really easy and quick to spin them up&lt;/p&gt;\n&lt;p&gt;this is because the container itself doesnt have a host operating system or any hardware - intel chip, apple chip etc - this is in the docker engine or runtime which we will look at in the architecture&lt;/p&gt;\n&lt;/aside&gt;\n&lt;/section&gt;\n&lt;section id=\"docker-architecture\" class=\"slide level2\"&gt;\n&lt;h2&gt;Docker Architecture&lt;/h2&gt;\n&lt;p&gt;&lt;img data-src=\"images/Screenshot%202023-08-30%20at%2011.31.56%20AM.png\" /&gt;&lt;/p&gt;\n&lt;aside class=\"notes\"&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Docker uses a client-server architecture. The Docker client talks to the Docker daemon.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;The Docker client - is the primary way that users interface with Docker via CLI&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;The Docker daemon does the heavy lifting of building, running, and distributing your Docker containers&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;The Docker client and daemon can run on the same system, or you can connect a Docker client to a remote Docker daemon. The Docker client and daemon communicate using a REST API, over UNIX sockets or a network interface.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Registry is a Repository for Docker images (e.g., Docker Hub) where you can store and share images.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Docker engine is a container runtime that runs on diffrent OS’s. Set up the isolated environment for your container&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/aside&gt;\n&lt;/section&gt;\n&lt;section id=\"mode-for-running-containers\" class=\"slide level2\"&gt;\n&lt;h2&gt;Mode for running containers&lt;/h2&gt;\n&lt;table style=\"width:100%;\"&gt;\n&lt;colgroup&gt;\n&lt;col style=\"width: 20%\" /&gt;\n&lt;col style=\"width: 6%\" /&gt;\n&lt;col style=\"width: 72%\" /&gt;\n&lt;/colgroup&gt;\n&lt;thead&gt;\n&lt;tr class=\"header\"&gt;\n&lt;th&gt;Mode&lt;/th&gt;\n&lt;th&gt;Run command&lt;/th&gt;\n&lt;th&gt;Use case&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr class=\"odd\"&gt;\n&lt;td&gt;Detached&lt;/td&gt;\n&lt;td&gt;&lt;code&gt;docker run -d&lt;/code&gt;&lt;/td&gt;\n&lt;td&gt;This runs the container in the &lt;strong&gt;background&lt;/strong&gt; so the container keeps running until the application process exits, or you stop the container. Detached mode is often used for production purposes.&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr class=\"even\"&gt;\n&lt;td&gt;Interactive + terminal&lt;/td&gt;\n&lt;td&gt;&lt;code&gt;docker run -it&lt;/code&gt;&lt;/td&gt;\n&lt;td&gt;This runs the container in the &lt;strong&gt;foreground&lt;/strong&gt; so you are unable to access the command prompt. Interactive mode is often used for development and testing.&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr class=\"odd\"&gt;\n&lt;td&gt;Remove everything once the container is done with its task&lt;/td&gt;\n&lt;td&gt;&lt;code&gt;docker run --rm&lt;/code&gt;&lt;/td&gt;\n&lt;td&gt;This mode is used on foreground containers that perform &lt;strong&gt;short-term tasks&lt;/strong&gt; such as tests or database backups. Once it is removed anything you may have downloaded or created in the container is also destroyed.&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;/section&gt;\n&lt;section id=\"lab-activity-5\" class=\"slide level2\"&gt;\n&lt;h2&gt;Lab Activity&lt;/h2&gt;\n&lt;p&gt;🟥 - I need help&lt;/p&gt;\n&lt;p&gt;🟨 - I’m still working&lt;/p&gt;\n&lt;p&gt;🟩 - I’m done&lt;/p&gt;\n&lt;p&gt;Complete Lab 2: Part 1&lt;/p&gt;\n&lt;/section&gt;\n&lt;section id=\"container-debugging\" class=\"slide level2\"&gt;\n&lt;h2&gt;Container Debugging&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Interactive mode&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;code&gt;docker exec&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Logging&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;pre&gt;&lt;code&gt;docker run -it -d ubuntu\ndocker container ls -a \ndocker exec -it CONTAINER_ID bash\n\ndocker container run -d --name mydb \\\n --name mydb \\\n -e MYSQL_ROOT_PASSWORD=my-secret-pw \\ \n mysql\n \n docker container logs mydb&lt;/code&gt;&lt;/pre&gt;\n&lt;div class=\"footer\"&gt;\n&lt;p&gt;🔍 Live code&lt;/p&gt;\n&lt;/div&gt;\n&lt;/section&gt;\n&lt;section id=\"lab-activity-6\" class=\"slide level2\"&gt;\n&lt;h2&gt;Lab Activity&lt;/h2&gt;\n&lt;p&gt;🟥 - I need help&lt;/p&gt;\n&lt;p&gt;🟨 - I’m still working&lt;/p&gt;\n&lt;p&gt;🟩 - I’m done&lt;/p&gt;\n&lt;p&gt;Complete Lab 2: Part 2&lt;/p&gt;\n&lt;/section&gt;\n&lt;section id=\"port-mapping-with-docker-run--p\" class=\"slide level2\"&gt;\n&lt;h2&gt;Port Mapping with &lt;code&gt;docker run -p&lt;/code&gt;&lt;/h2&gt;\n&lt;pre&gt;&lt;code&gt;docker pull httpd:alpine\ndocker pull httpd:latest\n\ndocker inspect --format=&#39;{{.Config.ExposedPorts}}&#39; httpd:latest\ndocker inspect --format=&#39;{{.Config.ExposedPorts}}&#39; httpd:alpine\n\ndocker run -p DockerHostPort:ApplicationPort\n\ndocker run -d -p 81:80 --name httpd-latest httpd:latest\ncurl http://localhost:81\n\ndocker run -d -p 80:80 --name httpd-alpine httpd:alpine\ncurl http://localhost:80&lt;/code&gt;&lt;/pre&gt;\n&lt;div class=\"footer\"&gt;\n&lt;p&gt;🔍 Live code&lt;/p&gt;\n&lt;/div&gt;\n&lt;/section&gt;\n&lt;section id=\"persisting-data-with-docker\" class=\"slide level2\"&gt;\n&lt;h2&gt;Persisting data with Docker&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;State is persistent information that is recorded and recalled later&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Containers are designed to be ephemeral e.g. stateless by default&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Data applications are usually stateful and more complex to deploy&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/section&gt;\n&lt;section id=\"docker-examples\" class=\"slide level2\"&gt;\n&lt;h2&gt;Docker examples&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;volume mount&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;bind mount&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;external storage&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;shared file system&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/section&gt;\n&lt;section id=\"putting-it-all-together\" class=\"slide level2\"&gt;\n&lt;h2&gt;Putting it all together&lt;/h2&gt;\n&lt;p&gt;https://github.com/rstudio/rstudio-docker-products/blob/dev/docker-compose.yml&lt;/p&gt;\n&lt;aside class=\"notes\"&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;docker-compose:&lt;/strong&gt; A tool for defining and running multi-container Docker applications.&lt;/li&gt;\n&lt;li&gt;Uses a YAML file to define services, networks, and volumes.&lt;/li&gt;\n&lt;li&gt;Simplifies the orchestration of complex applications.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/aside&gt;\n&lt;/section&gt;\n&lt;section id=\"lab-activity-7\" class=\"slide level2\"&gt;\n&lt;h2&gt;Lab Activity&lt;/h2&gt;\n&lt;p&gt;🟥 - I need help&lt;/p&gt;\n&lt;p&gt;🟨 - I’m still working&lt;/p&gt;\n&lt;p&gt;🟩 - I’m done&lt;/p&gt;\n&lt;p&gt;Complete Lab 2: Part 3 Complete Lab 2: Part 4&lt;/p&gt;\n&lt;/section&gt;\n&lt;section id=\"building-docker-images\" class=\"slide level2\"&gt;\n&lt;h2&gt;Building Docker Images&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Images are build using a Dockerfile or interactively “on-the-fly”&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Steps to version and share your images on Dockerhub (or a different repository)&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;make this a diagram Step 1: Commit Step 2: Tag Step 3: Push&lt;/p&gt;\n&lt;/section&gt;\n&lt;section id=\"lab-activity-8\" class=\"slide level2\"&gt;\n&lt;h2&gt;Lab Activity&lt;/h2&gt;\n&lt;p&gt;🟥 - I need help&lt;/p&gt;\n&lt;p&gt;🟨 - I’m still working&lt;/p&gt;\n&lt;p&gt;🟩 - I’m done&lt;/p&gt;\n&lt;p&gt;Complete Lab 2: Part 5&lt;/p&gt;\n&lt;/section&gt;\n&lt;section id=\"dockerfile-build-commands\" class=\"slide level2\"&gt;\n&lt;h2&gt;Dockerfile Build Commands&lt;/h2&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr class=\"header\"&gt;\n&lt;th&gt;Command&lt;/th&gt;\n&lt;th&gt;Description&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr class=\"odd\"&gt;\n&lt;td&gt;FROM&lt;/td&gt;\n&lt;td&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr class=\"even\"&gt;\n&lt;td&gt;ENV&lt;/td&gt;\n&lt;td&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr class=\"odd\"&gt;\n&lt;td&gt;COPY&lt;/td&gt;\n&lt;td&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr class=\"even\"&gt;\n&lt;td&gt;RUN&lt;/td&gt;\n&lt;td&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr class=\"odd\"&gt;\n&lt;td&gt;&lt;/td&gt;\n&lt;td&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr class=\"even\"&gt;\n&lt;td&gt;&lt;/td&gt;\n&lt;td&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr class=\"odd\"&gt;\n&lt;td&gt;&lt;/td&gt;\n&lt;td&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;/section&gt;\n&lt;section id=\"dockerfile-example\" class=\"slide level2\"&gt;\n&lt;h2&gt;Dockerfile Example&lt;/h2&gt;\n&lt;p&gt;Walk through Posit Connect &lt;a href=\"https://github.com/rstudio/rstudio-docker-products/blob/dev/connect/Dockerfile.ubuntu2204\"&gt;Dockerfile&lt;/a&gt;&lt;/p&gt;\n&lt;/section&gt;\n&lt;section id=\"activity\" class=\"slide level2\"&gt;\n&lt;h2&gt;Activity&lt;/h2&gt;\n&lt;p&gt;Complete Lab 2: Part 6&lt;/p&gt;\n&lt;/section&gt;\n&lt;section id=\"part-4-data-science-in-production\" class=\"slide level2\"&gt;\n&lt;h2&gt;Part 4: Data Science in Production&lt;/h2&gt;\n&lt;/section&gt;\n&lt;section id=\"data-science-in-production\" class=\"slide level2 content-dark\"&gt;\n&lt;h2 class=\"content-dark\"&gt;Data Science in Production&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Presentation Layer&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Processing Layer&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Data store Layer&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/section&gt;\n&lt;section id=\"choosing-the-right-presentation-layer\" class=\"slide level2\"&gt;\n&lt;h2&gt;Choosing the right presentation layer&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;&lt;a href=\"https://do4ds.com/chapters/sec1/1-2-proj-arch.html\"&gt;Alex’s flow chart&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;credit text&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/section&gt;\n&lt;section id=\"choosing-an-api\" class=\"slide level2\"&gt;\n&lt;h2&gt;Choosing an API&lt;/h2&gt;\n&lt;p&gt;&lt;img data-src=\"images/apis.png\" /&gt;&lt;/p&gt;\n&lt;/section&gt;\n&lt;section id=\"production-state\" class=\"slide level2\"&gt;\n&lt;h2&gt;Production “State”&lt;/h2&gt;\n&lt;p&gt;Questions to ask once your content is able to be consumed by your intended audience&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Where is it deployed?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Is it secure and accessible?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Is it maintainable?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Does it scale?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Is your code efficiently written?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Is it tested?&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/section&gt;\n&lt;section id=\"where-is-it-deployed\" class=\"slide level2\"&gt;\n&lt;h2&gt;Where is it deployed?&lt;/h2&gt;\n&lt;p&gt;list of PaaS / Caas and highlight Connect&lt;/p&gt;\n&lt;/section&gt;\n&lt;section id=\"lab-activity-9\" class=\"slide level2\"&gt;\n&lt;h2&gt;Lab Activity:&lt;/h2&gt;\n&lt;p&gt;🟥 - I need help&lt;/p&gt;\n&lt;p&gt;🟨 - I’m still working&lt;/p&gt;\n&lt;p&gt;🟩 - I’m done&lt;/p&gt;\n&lt;p&gt;Part 1: Host API on Posit Connect&lt;/p&gt;\n&lt;/section&gt;\n&lt;section id=\"is-it-secure\" class=\"slide level2\"&gt;\n&lt;h2&gt;Is it secure?&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Basic Auth&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;API keys&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Token-based&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/section&gt;\n&lt;section id=\"securing-credentials\" class=\"slide level2\"&gt;\n&lt;h2&gt;Securing credentials&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;username and password&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;centralized credential server&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;SSO&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/section&gt;\n&lt;section id=\"is-it-accessible\" class=\"slide level2\"&gt;\n&lt;h2&gt;Is it accessible?&lt;/h2&gt;\n&lt;p&gt;RBAC&lt;/p&gt;\n&lt;/section&gt;\n&lt;section id=\"lab-activity-10\" class=\"slide level2\"&gt;\n&lt;h2&gt;Lab Activity:&lt;/h2&gt;\n&lt;p&gt;🟥 - I need help&lt;/p&gt;\n&lt;p&gt;🟨 - I’m still working&lt;/p&gt;\n&lt;p&gt;🟩 - I’m done&lt;/p&gt;\n&lt;p&gt;Part 2:&lt;/p&gt;\n&lt;/section&gt;\n&lt;section id=\"is-it-maintainable\" class=\"slide level2\"&gt;\n&lt;h2&gt;Is it maintainable&lt;/h2&gt;\n&lt;p&gt;git-backed deploymnet&lt;/p&gt;\n&lt;/section&gt;\n&lt;section id=\"is-it-scalable\" class=\"slide level2\"&gt;\n&lt;h2&gt;Is it scalable?&lt;/h2&gt;\n&lt;p&gt;scaling up vs. scaling out&lt;/p&gt;\n&lt;p&gt;connect shiny resource options&lt;/p&gt;\n&lt;/section&gt;\n&lt;section id=\"is-your-code-efficient\" class=\"slide level2\"&gt;\n&lt;h2&gt;Is your code efficient?&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;data storage&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;computations&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;caches&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/section&gt;\n&lt;section id=\"is-it-tested\" class=\"slide level2\"&gt;\n&lt;h2&gt;Is it tested&lt;/h2&gt;\n&lt;p&gt;testing as part of CI/CD&lt;/p&gt;\n&lt;/section&gt;\n&lt;section id=\"section\" class=\"slide level2\"&gt;\n&lt;h2&gt;&lt;/h2&gt;\n&lt;div id=\"quarto-meta-markdown\" class=\"hidden\"&gt;\n&lt;p&gt;&lt;span class=\"hidden\" data-render-id=\"quarto-metatitle\"&gt;Devops for Data Scientists - DevOps for Data Scientists&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-twittercardtitle\"&gt;Devops for Data Scientists - DevOps for Data Scientists&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-ogcardtitle\"&gt;Devops for Data Scientists - DevOps for Data Scientists&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-metasitename\"&gt;Devops for Data Scientists&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-twittercarddesc\"&gt;| | Wifi: Posit Conf 2023 | password: conf2023&lt;/span&gt; &lt;span class=\"hidden\" data-render-id=\"quarto-ogcardddesc\"&gt;| | Wifi: Posit Conf 2023 | password: conf2023&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;div class=\"footer footer-default\"&gt;\n&lt;p&gt;&lt;a href=\"https://github.com/posit-conf-2023/DevOps\" class=\"uri\"&gt;https://github.com/posit-conf-2023/DevOps&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;/section&gt;&lt;/section&gt;\n    &lt;/div&gt;\n  &lt;/div&gt;\n\n  &lt;script&gt;window.backupDefine = window.define; window.define = undefined;&lt;/script&gt;\n  &lt;script src=\"../site_libs/revealjs/dist/reveal.js\"&gt;&lt;/script&gt;\n  &lt;!-- reveal.js plugins --&gt;\n  &lt;script src=\"../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js\"&gt;&lt;/script&gt;\n  &lt;script src=\"../site_libs/revealjs/plugin/pdf-export/pdfexport.js\"&gt;&lt;/script&gt;\n  &lt;script src=\"../site_libs/revealjs/plugin/reveal-menu/menu.js\"&gt;&lt;/script&gt;\n  &lt;script src=\"../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js\"&gt;&lt;/script&gt;\n  &lt;script src=\"../site_libs/revealjs/plugin/reveal-chalkboard/plugin.js\"&gt;&lt;/script&gt;\n  &lt;script src=\"../site_libs/revealjs/plugin/quarto-support/support.js\"&gt;&lt;/script&gt;\n  \n\n  &lt;script src=\"../site_libs/revealjs/plugin/notes/notes.js\"&gt;&lt;/script&gt;\n  &lt;script src=\"../site_libs/revealjs/plugin/search/search.js\"&gt;&lt;/script&gt;\n  &lt;script src=\"../site_libs/revealjs/plugin/zoom/zoom.js\"&gt;&lt;/script&gt;\n  &lt;script src=\"../site_libs/revealjs/plugin/math/math.js\"&gt;&lt;/script&gt;\n  &lt;script&gt;window.define = window.backupDefine; window.backupDefine = undefined;&lt;/script&gt;\n\n  &lt;script&gt;\n\n      // Full list of configuration options available at:\n      // https://revealjs.com/config/\n      Reveal.initialize({ \n        // Display controls in the bottom right corner\n        controls: false,\n\n        // Help the user learn the controls by providing hints, for example by\n        // bouncing the down arrow when they first encounter a vertical slide\n        controlsTutorial: false,\n\n        // Determines where controls appear, \"edges\" or \"bottom-right\"\n        controlsLayout: 'edges',\n\n        // Visibility rule for backwards navigation arrows; \"faded\", \"hidden\"\n        // or \"visible\"\n        controlsBackArrows: 'faded',\n\n        // Display a presentation progress bar\n        progress: true,\n\n        // Display the page number of the current slide\n        slideNumber: c/t,\n\n        // 'all', 'print', or 'speaker'\n        showSlideNumber: 'all',\n\n        // Add the current slide number to the URL hash so that reloading the\n        // page/copying the URL will return you to the same slide\n        hash: true,\n\n        // Start with 1 for the hash rather than 0\n        hashOneBasedIndex: false,\n\n        // Flags if we should monitor the hash and change slides accordingly\n        respondToHashChanges: true,\n\n        // Push each slide change to the browser history\n        history: true,\n\n        // Enable keyboard shortcuts for navigation\n        keyboard: true,\n\n        // Enable the slide overview mode\n        overview: true,\n\n        // Disables the default reveal.js slide layout (scaling and centering)\n        // so that you can use custom CSS layout\n        disableLayout: false,\n\n        // Vertical centering of slides\n        center: false,\n\n        // Enables touch navigation on devices with touch input\n        touch: true,\n\n        // Loop the presentation\n        loop: false,\n\n        // Change the presentation direction to be RTL\n        rtl: false,\n\n        // see https://revealjs.com/vertical-slides/#navigation-mode\n        navigationMode: 'linear',\n\n        // Randomizes the order of slides each time the presentation loads\n        shuffle: false,\n\n        // Turns fragments on and off globally\n        fragments: true,\n\n        // Flags whether to include the current fragment in the URL,\n        // so that reloading brings you to the same fragment position\n        fragmentInURL: false,\n\n        // Flags if the presentation is running in an embedded mode,\n        // i.e. contained within a limited portion of the screen\n        embedded: false,\n\n        // Flags if we should show a help overlay when the questionmark\n        // key is pressed\n        help: true,\n\n        // Flags if it should be possible to pause the presentation (blackout)\n        pause: true,\n\n        // Flags if speaker notes should be visible to all viewers\n        showNotes: false,\n\n        // Global override for autoplaying embedded media (null/true/false)\n        autoPlayMedia: null,\n\n        // Global override for preloading lazy-loaded iframes (null/true/false)\n        preloadIframes: null,\n\n        // Number of milliseconds between automatically proceeding to the\n        // next slide, disabled when set to 0, this value can be overwritten\n        // by using a data-autoslide attribute on your slides\n        autoSlide: 0,\n\n        // Stop auto-sliding after user input\n        autoSlideStoppable: true,\n\n        // Use this method for navigation when auto-sliding\n        autoSlideMethod: null,\n\n        // Specify the average time in seconds that you think you will spend\n        // presenting each slide. This is used to show a pacing timer in the\n        // speaker view\n        defaultTiming: null,\n\n        // Enable slide navigation via mouse wheel\n        mouseWheel: false,\n\n        // The display mode that will be used to show slides\n        display: 'block',\n\n        // Hide cursor if inactive\n        hideInactiveCursor: true,\n\n        // Time before the cursor is hidden (in ms)\n        hideCursorTime: 5000,\n\n        // Opens links in an iframe preview overlay\n        previewLinks: false,\n\n        // Transition style (none/fade/slide/convex/concave/zoom)\n        transition: 'none',\n\n        // Transition speed (default/fast/slow)\n        transitionSpeed: 'default',\n\n        // Transition style for full page slide backgrounds\n        // (none/fade/slide/convex/concave/zoom)\n        backgroundTransition: 'none',\n\n        // Number of slides away from the current that are visible\n        viewDistance: 3,\n\n        // Number of slides away from the current that are visible on mobile\n        // devices. It is advisable to set this to a lower number than\n        // viewDistance in order to save resources.\n        mobileViewDistance: 2,\n\n        // The \"normal\" size of the presentation, aspect ratio will be preserved\n        // when the presentation is scaled to fit different resolutions. Can be\n        // specified using percentage units.\n        width: 1600,\n\n        height: 900,\n\n        // Factor of the display size that should remain empty around the content\n        margin: 0.1,\n\n        math: {\n          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',\n          config: 'TeX-AMS_HTML-full',\n          tex2jax: {\n            inlineMath: [['\\\\(','\\\\)']],\n            displayMath: [['\\\\[','\\\\]']],\n            balanceBraces: true,\n            processEscapes: false,\n            processRefs: true,\n            processEnvironments: true,\n            preview: 'TeX',\n            skipTags: ['script','noscript','style','textarea','pre','code'],\n            ignoreClass: 'tex2jax_ignore',\n            processClass: 'tex2jax_process'\n          },\n        },\n\n        // reveal.js plugins\n        plugins: [\n          RevealMath,\n          RevealNotes,\n          RevealSearch,\n          RevealZoom\n        ]\n      });\n    &lt;/script&gt;\n    &lt;script id = \"quarto-html-after-body\" type=\"application/javascript\"&gt;\n    window.document.addEventListener(\"DOMContentLoaded\", function (event) {\n      const toggleBodyColorMode = (bsSheetEl) =&gt; {\n        const mode = bsSheetEl.getAttribute(\"data-mode\");\n        const bodyEl = window.document.querySelector(\"body\");\n        if (mode === \"dark\") {\n          bodyEl.classList.add(\"quarto-dark\");\n          bodyEl.classList.remove(\"quarto-light\");\n        } else {\n          bodyEl.classList.add(\"quarto-light\");\n          bodyEl.classList.remove(\"quarto-dark\");\n        }\n      }\n      const toggleBodyColorPrimary = () =&gt; {\n        const bsSheetEl = window.document.querySelector(\"link#quarto-bootstrap\");\n        if (bsSheetEl) {\n          toggleBodyColorMode(bsSheetEl);\n        }\n      }\n      toggleBodyColorPrimary();  \n      const tabsets =  window.document.querySelectorAll(\".panel-tabset-tabby\")\n      tabsets.forEach(function(tabset) {\n        const tabby = new Tabby('#' + tabset.id);\n      });\n      const isCodeAnnotation = (el) =&gt; {\n        for (const clz of el.classList) {\n          if (clz.startsWith('code-annotation-')) {                     \n            return true;\n          }\n        }\n        return false;\n      }\n      const clipboard = new window.ClipboardJS('.code-copy-button', {\n        text: function(trigger) {\n          const codeEl = trigger.previousElementSibling.cloneNode(true);\n          for (const childEl of codeEl.children) {\n            if (isCodeAnnotation(childEl)) {\n              childEl.remove();\n            }\n          }\n          return codeEl.innerText;\n        }\n      });\n      clipboard.on('success', function(e) {\n        // button target\n        const button = e.trigger;\n        // don't keep focus\n        button.blur();\n        // flash \"checked\"\n        button.classList.add('code-copy-button-checked');\n        var currentTitle = button.getAttribute(\"title\");\n        button.setAttribute(\"title\", \"Copied!\");\n        let tooltip;\n        if (window.bootstrap) {\n          button.setAttribute(\"data-bs-toggle\", \"tooltip\");\n          button.setAttribute(\"data-bs-placement\", \"left\");\n          button.setAttribute(\"data-bs-title\", \"Copied!\");\n          tooltip = new bootstrap.Tooltip(button, \n            { trigger: \"manual\", \n              customClass: \"code-copy-button-tooltip\",\n              offset: [0, -8]});\n          tooltip.show();    \n        }\n        setTimeout(function() {\n          if (tooltip) {\n            tooltip.hide();\n            button.removeAttribute(\"data-bs-title\");\n            button.removeAttribute(\"data-bs-toggle\");\n            button.removeAttribute(\"data-bs-placement\");\n          }\n          button.setAttribute(\"title\", currentTitle);\n          button.classList.remove('code-copy-button-checked');\n        }, 1000);\n        // clear code selection\n        e.clearSelection();\n      });\n      function tippyHover(el, contentFn) {\n        const config = {\n          allowHTML: true,\n          content: contentFn,\n          maxWidth: 500,\n          delay: 100,\n          arrow: false,\n          appendTo: function(el) {\n              return el.closest('section.slide') || el.parentElement;\n          },\n          interactive: true,\n          interactiveBorder: 10,\n          theme: 'light-border',\n          placement: 'bottom-start'\n        };\n          config['offset'] = [0,0];\n          config['maxWidth'] = 700;\n        window.tippy(el, config); \n      }\n      const noterefs = window.document.querySelectorAll('a[role=\"doc-noteref\"]');\n      for (var i=0; i&lt;noterefs.length; i++) {\n        const ref = noterefs[i];\n        tippyHover(ref, function() {\n          // use id or data attribute instead here\n          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');\n          try { href = new URL(href).hash; } catch {}\n          const id = href.replace(/^#\\/?/, \"\");\n          const note = window.document.getElementById(id);\n          return note.innerHTML;\n        });\n      }\n      const findCites = (el) =&gt; {\n        const parentEl = el.parentElement;\n        if (parentEl) {\n          const cites = parentEl.dataset.cites;\n          if (cites) {\n            return {\n              el,\n              cites: cites.split(' ')\n            };\n          } else {\n            return findCites(el.parentElement)\n          }\n        } else {\n          return undefined;\n        }\n      };\n      var bibliorefs = window.document.querySelectorAll('a[role=\"doc-biblioref\"]');\n      for (var i=0; i&lt;bibliorefs.length; i++) {\n        const ref = bibliorefs[i];\n        const citeInfo = findCites(ref);\n        if (citeInfo) {\n          tippyHover(citeInfo.el, function() {\n            var popup = window.document.createElement('div');\n            citeInfo.cites.forEach(function(cite) {\n              var citeDiv = window.document.createElement('div');\n              citeDiv.classList.add('hanging-indent');\n              citeDiv.classList.add('csl-entry');\n              var biblioDiv = window.document.getElementById('ref-' + cite);\n              if (biblioDiv) {\n                citeDiv.innerHTML = biblioDiv.innerHTML;\n              }\n              popup.appendChild(citeDiv);\n            });\n            return popup.innerHTML;\n          });\n        }\n      }\n    });\n    &lt;/script&gt;\n    &lt;/body&gt;\n&lt;/html&gt;"
  }
]