---
title: "Devops for Data Scientists"
subtitle: "wifi name:xyz wifi password:123 "
title-slide-attributes: 
  data-background-color: white
  data-background-image: _extensions/positconfslides/assets/backgrounds/toc-light.svg
  data-background-size: contain
format:
  positconfslides-revealjs: 
    chalkboard: true
    slide-number: true
    footer: <https://github.com/posit-conf-2023/devops>
    incremental: false
    code-copy: true
    center-title-slide: false
    code-link: true
    code-overflow: wrap
    highlight-style: a11y
    width: "3000"
    height: "2000"
    filters:
      - positconfslides
---

## Part 1: Introductions, setup, & workshop overview

## Workshop Goals

-   To understand how devops can help you in your work as data scientists

-   To understand the main principles of Devops

-   To get hands-on experience putting code into production using common devops workflows

-   To leave the workshop with some "assets" and skills you can use in your work

## Agenda & Lab Overview

+------------------------------------+------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Section/Time                       | Topics                                               | Labs                                                                                                                                                          |
+====================================+======================================================+===============================================================================================================================================================+
| Part 1                             | Workshop overview                                    | Infrastructure & wifi setup                                                                                                                                   |
|                                    |                                                      |                                                                                                                                                               |
|                                    | Logistics & setup                                    | Optional: Linux Refresher                                                                                                                                     |
|                                    |                                                      |                                                                                                                                                               |
|                                    | Introductions                                        |                                                                                                                                                               |
+------------------------------------+------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Part 2: Devops Principles          | Introduction to devops                               | Lab 1: Deploy your own Quarto website on Github Pages using GitHub Actions CI/CD                                                                              |
|                                    |                                                      |                                                                                                                                                               |
|                                    | Version control & github                             |                                                                                                                                                               |
|                                    |                                                      |                                                                                                                                                               |
|                                    | CI/CD                                                |                                                                                                                                                               |
|                                    |                                                      |                                                                                                                                                               |
|                                    | Reproducing workflows and environments               |                                                                                                                                                               |
+------------------------------------+------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Part 3: Docker for Data Scientists | How and why data scientists use docker in production | Lab #2: Write your own Dockerfile to deploy Open Source Shiny Server on [Docker playground](https://labs.play-with-docker.com/) and host an app on the server |
|                                    |                                                      |                                                                                                                                                               |
|                                    | Docker: overview and architecture                    |                                                                                                                                                               |
|                                    |                                                      |                                                                                                                                                               |
|                                    | Building docker images and containers                |                                                                                                                                                               |
|                                    |                                                      |                                                                                                                                                               |
|                                    | Ports & networking                                   |                                                                                                                                                               |
+------------------------------------+------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Part 4: Data Science in Production | Choosing your deployment method                      | Lab #3: Create an API wrapper around a trained prediction model and host it on Posit Connect                                                                  |
|                                    |                                                      |                                                                                                                                                               |
|                                    | APIs and when to use them                            |                                                                                                                                                               |
|                                    |                                                      |                                                                                                                                                               |
|                                    | Just enough auth                                     |                                                                                                                                                               |
|                                    |                                                      |                                                                                                                                                               |
|                                    | Logging & metrics & testing                          |                                                                                                                                                               |
+------------------------------------+------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Part 5: Discussion                 | Course feedback                                      | None                                                                                                                                                          |
|                                    |                                                      |                                                                                                                                                               |
|                                    | Questions for the team                               |                                                                                                                                                               |
|                                    |                                                      |                                                                                                                                                               |
|                                    | Working with other teams                             |                                                                                                                                                               |
+------------------------------------+------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

## Supplemental Materials

-   Linux
-   vim
-   Git
-   Cheat sheets

## Most important workshop commands

-   cd
-   ls
-   pwd
-   touch
-   mkdir
-   vim
-   curl
-   echo
-   env
-   \$PATH

## What we won't cover

-   How to become a devops engineer

-   Python-based workflows

-   In-depth security and auth practices

## Meet your instructors

::: panel-tabset
## Rika

![](images/rika_bio-01.jpeg){width="25%"}

-   Solutions Engineer at Posit

-   Former Data Scientist and Data Engineer

## Andrie

## David

![](images/edavidaja.jpeg){width="25%"}

-   David Aja is a Solutions Engineer at Posit. Before joining Posit, he worked as a data scientist in the public sector.

## Gagan

![](images/gagan.png){width="25%"}

-   Gagandeep Singh is a former software engineer and data scientist who has worked in a variety of cross-technology teams before joining Posit as a Solutions Engineer.

## Sam

![](images/sam-workweek-2023-large.jpeg){width="25%"}

-   Sam Edwardes is a Solutions Engineer at Posit. He is passionate about open source software and data science. Before joining Posit Sam consulted for many different companies as a Consultant at Deloitte.
:::

## Solutions Engineering at Posit

![](images/sol-eng.png){width="25%"}

-   Posit's Solutions Engineering team aims to shrink the distance between the needs of Posit's customers and our Pro and Open Source offerings, leading with curiosity and technical excellence.

-   Our customer-facing work helps our customers deploy, install, configure, and use our Pro products.

## Special Thanks to Alex Gold!

![](images/_40A8864.jpg){width="206" height="140"}

Author of [Devops for Data Science](www.do4ds.com)

Posit Solutions Engineering Team Director

## Introduce yourself to your neighbor

Take 5 minutes and introduce yourself to your neighbors.

-   How do you think devops can help you in your work?

-   What are you most looking forward to in the conference?

## Logistics & Workshop Setup {.toc-people-dark}

## Pre-workshop Install {.brackets-light}

We encourage you to set up the following systems prior to the start of the workshop. We will also set aside time during the workshop to install and troubleshoot.

1.  Install [git](https://git-scm.com/downloads) on your laptop. You can check if git is already installed by typing `git --version` in the terminal.
2.  If you do not have a github account please create a [personal](https://docs.github.com/en/get-started/signing-up-for-github/signing-up-for-a-new-github-account) account.
3.  Make sure that you have a text editor that you are comfortable using. For example, Rstudio [IDE](https://www.rstudio.com/categories/rstudio-ide/), [vscode](https://code.visualstudio.com/download), [sublime](https://www.sublimetext.com/3).
4.  Create an account at [Docker Hub](https://hub.docker.com/).
5.  Download [Docker Desktop](https://www.docker.com/products/docker-desktop/).
6.  Download [quarto](https://quarto.org/docs/download/).
7.  Sign up for our workshop Discord channel

## Wifi & Workshop Install {.brackets-light}

Wifi Name:

Wifi: Password:

Is your wifi working? If not, let one of the instructors/TA's know as soon as possible.

## Workshop Install

Login to http://rstd.io/class, use the provided username and password and access Posit Workbench and Posit Connect.

Login to Docker Playground with your Docker Hub username and password.

## Documentation & Communication {.brackets-light}

-   All documents including slides are available at this github [repo](https://github.com/posit-conf-2023/devops)
-   We will use the Discord channel for communicating code snippets and answering questions
-   "Posit" Notes system for TA support during exercises and labs
    -   üü• - I need help
    -   üü® - I'm still working
    -   üü© - I'm done

## Daily Schedule {.brackets-light}

üìÖ September 17 and 18, 2023\
‚è∞ 09:00 - 17:00\
üè® ROOM: TBD\
‚úçÔ∏èTBD

+---------------+--------------------+
| Time          | Topic              |
+===============+====================+
| 10:30 - 11:00 | Break              |
+---------------+--------------------+
| 12:30 - 13:30 | Lunch              |
+---------------+--------------------+
| 15:00 - 15:30 | Break              |
+---------------+--------------------+

## Code of Conduct {.brackets-light}

https://posit.co/code-of-conduct/

## Part 2: Devops Principles

## A very brief history

-   Development of system of practice in the late 2000's in software and IT online communities

-   Developers often siloed from operations teams resulting in inefficient processes

-   Long development cycles and monolithic environments made it difficult to quickly iterate and deploy

-   Software stacks used different languages, frameworks, databases

-   Devops built on agile methodologies used in software dev and extended it to operations

-   Microservices architectures become more popular

-   Movement to integrate security into devops cycles

## Principles of Devops {.toc-people-dark}

![](images/Screenshot%202023-08-29%20at%203.32.37%20PM.png){width="435"}

-   Collaboration

-   Automation

-   CI/CD

-   Rapid feedback loops

-   Culture change

::: notes
**DevOps** is a combination of software development (dev) and operations (ops). It is defined as a software engineering methodology which aims to integrate the work of development teams and operations teams by facilitating a culture of collaboration and shared responsibility.
:::

::: footer
Illustration & Definition credit:Gitlab, https://about.gitlab.com/topics/devops/
:::

## Has this ever happened to you?

::: incremental
-   You come back to code from a year ago and now it doesnt run!

-   Your boss asks you to share that Shiny app with a client but the dev team is too busy working on their roadmap to help you deploy it somewhere.

-   You need to share your prediction model (created in R) with the Engineering team but they only code in Java.

-   What other problems have you ran into that could possibly be solved with devops practices or tools?
:::

## Why should data scientists/analysts care about devops?

-   Building and delivering software includes models, visualizations, data transformations & data applications

-   Practices such as automation, collaboration, testing, and iterative improvement can dramatically improve data work and improve reproducibility

-   Developers of code are often also asked to help "operationalize" their code

-   Improve collaboration & communication with engineering, ops, IT, and security teams

## Responsibility of the analyst

![](images/Screenshot%202023-08-22%20at%203.26.22%20PM.png)

## The CI/CD Pipeline

![](images/cicd.png)

::: notes
Automation is a core principle for achieving DevOps success and CI/CD is a critical component. CI/CD comprises of continuous integration and continuous delivery or continuous deployment. Put together, they form a "CI/CD pipeline"---a series of automated workflows that help DevOps teams cut down on manual tasks:

Continuous integration (CI) automatically builds, tests, and integrates code changes within a shared repository; then Continuous delivery (CD) automatically delivers code changes to production-ready environments for approval; or Continuous deployment (CD) automatically deploys code changes to customers directly.
:::

## CI/CD Toolkit

-   Environments
-   Version Control
-   Git workflows
-   Build tools
    -   YAML
    -   package managers
    -   CI/CD platforms

## Environments

Content is deployed (and code is promoted) across different environments with different intended audiences

+-----------------------------------------------------------------------+--------------------------------------------------------------------------+--------------------------------+
| Dev                                                                   | Test                                                                     | Prod                           |
+=======================================================================+==========================================================================+================================+
| a place for data scientists to do exploratory analysis and experiment | as similar to prod as possible                                           | separate from dev and test     |
|                                                                       |                                                                          |                                |
| often just your local desktop                                         | code testing                                                             | created using code             |
|                                                                       |                                                                          |                                |
| data science "sandbox" with data that's as close to real as possible  | data validation                                                          | code promotion process + tests |
|                                                                       |                                                                          |                                |
| access to R/Python packages                                           | in software dev world includes integration, unit, and regression testing | completely automatic           |
+-----------------------------------------------------------------------+--------------------------------------------------------------------------+--------------------------------+

## Version Control & Workflows

![](images/Screenshot%202023-08-23%20at%2011.20.04%20AM.png)

::: notes
Continuous Integration - an an iterative process to build, test, collaborate on your code to above environments

Tools include code promotion, code reviews, process for your team, how to name things, pull requests, version control with git, feature branching, automatic tests
:::

## Lab Activity

üü• - I need help

üü® - I'm still working

üü© - I'm done

Part 1 of the Deploy Quarto Site with GHA Lab

## Build tools

An automatic process to build, test, and deploy your code to above environments

Tools include config files, `config` package, CI/CD software such as GHA, automatic tests

![](images/Screenshot%202023-08-23%20at%202.49.21%20PM.png)

::: footer
Illustration credit:
:::

## Power of YAML

-   YAML Ain't Markup Language

-   communication of data between people and computers.

-   human friendly

-   everything is a key value pair and interpreted as maps or dictionaries

-   used for configuration files across many execution environments including Docker, virtual machines, K8s, helm, IaaS, etc

## JSON

```{json}

[
  {
    "name": "William",
    "last name": "Bailey",
    "dob": 1962,
    "nickname": "Axl Rose",
    "instruments": [
      "vocals",
      "piano"
    ]
  },
  {
    "name": "Saul",
    "last name": "Hudson",
    "dob": 1965,
    "nickname": "Slash",
    "instruments": [
      "guitar"
    ]
  }
]

```

## XML

```{xml}
<?xml version="1.0" encoding="UTF-8" ?>
<root>
  <row>
    <name>William</name>
    <dob>1962</dob>
    <nickname>Axl Rose</nickname>
    <instruments>vocals</instruments>
    <instruments>piano</instruments>
    <last_name>Bailey</last_name>
  </row>
  <row>
    <name>Saul</name>
    <dob>1965</dob>
    <nickname>Slash</nickname>
    <instruments>guitar</instruments>
    <last_name>Hudson</last_name>
  </row>
</root>
```

## YAML

```{yaml}
- name: William
  last name: Bailey
  dob: 1962
  nickname: Axl Rose
  instruments:
    - vocals
    - piano

- name: Saul
  last name: Hudson
  dob: 1965
  nickname: Slash
  instruments:
    - guitar
```

## YAML syntax

-   whitespace indentation is used to denote structure, no need for quotes nor brackets

-   Colons separate keys and their values

-   Dashes are used to denote a list

-   https://github.com/sd031/yaml-crash-course/blob/main/full_example.yaml

## Examples

-   https://github.com/rstudio/rstudio-docker-products/blob/dev/docker-compose.yml
-   https://github.com/Rikagx/personal-website/blob/main/.github/workflows/publish.yaml

## Lab Activity

üü• - I need help

üü® - I'm still working

üü© - I'm done

Inspect your \_quarto.yml file and identify what each part of it does using the quarto site.

## Layers of reproducibility

+---------------+---------------------------------+
| Layer         | Contents                        |
+===============+=================================+
| Packages      | R + Python Packages             |
+---------------+---------------------------------+
| System        | R + Python Language Versions    |
|               |                                 |
|               | System Libraries                |
|               |                                 |
|               | Operating System + dependencies |
+---------------+---------------------------------+
| Hardware      | Virtual Hardware                |
|               |                                 |
|               | Physical Hardware               |
+---------------+---------------------------------+

:::notes 
- Let's say someone wanted to reproduce your project including your code and your environment. Make a list of the layers that would need to be reproduced on their machine. (For example, a layer would be the version of R that you're using)

options("repos") Run .libPaths()

-   Hints:

    -   Inspect your renv.lock file.
    -   Where are your packages being pulled from? Confirm by typing `options("repos")`.
        -   You can modify your package repository by running `options("repos" = c("<REPO-NAME>" = "https://your-repository-url.com"))` in your RStudio console.
    -   Visit the webpage where packages are being pulled from and see if you can identify package dependencies. Are packages downloaded as binaries or from source?
    -   What are your server and OS dependencies? (If you are not sure which distribution of Linux you are using, you can find it by typing `cat /etc/*-release` in your terminal)

-   In your day-to-day work, what's the hardest reproducibility challenge?

:::

## Packages vs. Libraries vs. Repositories

**Package** - contains code, functions, data, and documentation. Can be be distributed as SOURCE (a directory with all package components), [BINARIES](https://solutions.posit.co/envs-pkgs/environments/repositories/index.html#binary-packages) (contains files in OS-specific format) or as a BUNDLE (compressed file containing package components, similar to source).

**Library** - is a directory where packages are installed. You can have user-level or project-level libraries. Run `.libPaths()` to see yours. To use a package in has to be installed in a library with `install.packages()` and then loaded into memory with `library(x)` .

**Repository** - a collection of packages. CRAN is a public external repository that is a network of servers that distribute R along with R packages.

## Renv workflow

![](images/Screenshot%202023-09-06%20at%208.31.22%20PM.png)

:::notes 
1. Use a version control system e.g.[git](https://git-scm.com/) with [GitHub](https://github.com/)

2.  One user (perhaps yourself) should explicitly initialize `renv` in the project, via [`renv::init()`](https://rstudio.github.io/renv/reference/init.html). This will create the initial `renv` lockfile, and also write the `renv` auto-loaders to the project's `.Rprofile` and `renv/activate.R`. These will ensure the right version of `renv` is downloaded and installed for your collaborators when they start in this project.

3.  Using a branching strategy push your code alongside the generated lockfile `renv.lock`. Be sure to also share the generated auto-loaders in `.Rprofile` and `renv/activate.R`.

4.  When a collaborator first launches in this project, `renv` should automatically bootstrap itself, thereby downloading and installing the appropriate version of `renv` into the project library. After this has completed, they can then use [`renv::restore()`](https://rstudio.github.io/renv/reference/restore.html) to restore the project library locally on their machine. 
:::

## Lab Activity

üü• - I need help

üü® - I'm still working

üü© - I'm done

Complete Part 2 of Lab: Deploy Quarto with GHA including the exercises

## Mechanisms for reproducibility

\*\* make this a diagram starting from least to most reproducibility

-   documenting state & version control

-   virtual environments (`renv`, `venv`) + package management

-   Containerization & docker

-   Infrastructure as Code

## Is version control secure?

- our code is still saved locally
- How do we make sure that the code we push to Github (or elsewhere) is secure?

## A short auth teaser

- We can use a variety of data sharing "transfer protocols"
- protocols specify what kind of traffic is moving between 2 machines
- a port specifies where to direct the traffic

| http    | https    | SSH     | git       |
|---------|----------|---------|-----------|
| port 80 | port 443 | port 22 | port 9418 |

## Image of ports and how they work

-   notes: A port is a virtual point where network connections start and end. Ports are software-based and managed by a computer's operating system. Each port is associated with a specific process or service. Ports allow computers to easily differentiate between different kinds of traffic: emails go to a different port than webpages, for instance, even though both reach a computer over the same Internet connection.

-   Add picture of client box, server box connected by line with different ports for each box

-   Localhost: `ping localhost - this computer/host`

![](images/ports-01.jpg)

## Lab Activity

üü• - I need help

üü® - I'm still working

üü© - I'm done

Part 3 of Lab: Deploy Quarto with GHA including the exercises

## Automating your build

- GHA is one tool to automate developer workflows
- CI/CD is just one example of these workflows
- Run on github servers


:::notes
- A github action allows us to create workflows that are triggered by a github action such as a push or pull to a branch

-   Workflows can include tests, markdown renders, shell scripts, cron jobs, or deployments. They can be as simple or as complicated as you need. Open-source community provides a ton of examples of actions.

-   Open source collection of "available" actions

create a blank repo and show actions workflows
https://github.com/Rikagx/workshop_testing/blob/master/.github/workflows/publish.yaml
github.com/actions
https://github.com/r-lib/actions
:::


## Lab Activity

üü• - I need help

üü® - I'm still working

üü© - I'm done

Part 4 of Lab: Deploy Quarto with GHA including the exercises

## Part 3: Docker for Data Scientists

## Introduction to Docker

-   Open-source tool.
-   Package applications and its dependencies in a unit called a container.
-   Create isolated environments for different experiments.
-   Share work with colleagues without environment setup issues.

::: notes
Docker is a tool that allows you to virtualize (put your computer in the cloud) everything you need to create an application or in this case a data science product You can share containers with colleagues without requiring them to have to set up their own local machines Without something like this, in order to recreate or test code that someone else wrote, you'd need every developer to download the same dependencies, configurations, scripts and make sure that it ran on their machine - whether thats a mac, or windows, or linux or some other operating system
:::

## How can docker help data scientists?

## Portability

-   diagram r code creates model/api in docker container
-   uses gha to create docker image

## Isolation

## Consistency

::: notes
-   Data scientists benefit from Docker's consistency and reproducibility.

-   Create isolated environments for different experiments.

-   Share work with colleagues without environment setup issues.

-   **Consistency:** Containers ensure that applications run the same way across different environments.

-   **Isolation:** Containers isolate applications and their dependencies, preventing conflicts.

-   **Portability:** Containers can run on any system that supports Docker, reducing "it works on my machine" issues.
:::

## Lifecycle

![](images/lifecycle.png)

::: footer
Illustration credit: Alex Gold, do4ds.com
:::

## Lifecycle Example

``` bash
docker pull postgres:12
docker pull postgres:latest
docker container ls -a
docker run -d -e POSTGRES_PASSWORD=mysecretpassword --name postgres_early imageID
docker run -d -e POSTGRES_PASSWORD=mysecretpassword --name postgres_new imageID
docker container ls -a
docker stop
docker restart
```

::: footer
üîç Live code
:::

::: notes
a dockerfile is the recipe to build a docker images this recipe is stored in some sort of repository, this can be private, public, or dockerhub - which is the default a docker image contains lightweight instructions to create your application. Docker images use something called layers which makes it super easy and quick to update. Layers start at a base layer which is usually the linux operating system and then they go up to the application layer. a container is the environment for a running process of an image - so if an image is running then its using a container instance. You can have multiple containers running at the same time. But once you delete it everything inside of it goes away.

Let's see an example of what this looks like in practice. Lets say we need to use a postgres sql database for some testing - but we want to test using an older and a newer version of postgres.

Lets go to Dockerhub and search for it. We can see official images but there are also thousands of them created by people- hub only has images not dockerfiles or containers themselves. docker image ls - lets list all the images that we have docker pull postgres:12 - see how its pulling and extracting all these layers - but what if we want a newer version or what if we need to run both versions on our machine

docker pull postgres:latest - notice how some of these layers already exist so it takes a lot less time

Lets go on dockerhub and see if we can understand a bit more about the layers https://hub.docker.com/layers/library/postgres/12/images/sha256-a97fd76ab09599e2ddc15c90a87f9a4a2a60551d99f8e7397f12a1d606d7f0ab?context=explore -

we can see that there are a lot of layers but its hard to understand what exactly is happening - lets look at the dockerfile that shows us the recipe for postgres - this is usually saved in a [github](https://github.com/docker-library/docs/blob/master/postgres/README.md) repo - not on dockerhub which is just images

every docker file starts with a from command - this is the base layers that starts the image, then we are running some things, copying , env variables, and starting

lets run the image and see
:::

## Virtual Machine vs. Container

![](images/Screenshot%202023-09-03%20at%209.56.54%20AM.png)

::: notes
containers are very lightweight which makes it really easy and quick to spin them up

this is because the container itself doesnt have a host operating system or any hardware - intel chip, apple chip etc - this is in the docker engine or runtime which we will look at in the architecture
:::

## Docker Architecture

![](images/Screenshot%202023-08-30%20at%2011.31.56%20AM.png)

::: notes
-   Docker uses a client-server architecture. The Docker client talks to the Docker daemon.

-   The Docker client - is the primary way that users interface with Docker via CLI

-   The Docker daemon does the heavy lifting of building, running, and distributing your Docker containers

-   The Docker client and daemon can run on the same system, or you can connect a Docker client to a remote Docker daemon. The Docker client and daemon communicate using a REST API, over UNIX sockets or a network interface.

-   Registry is a Repository for Docker images (e.g., Docker Hub) where you can store and share images.

-   Docker engine is a container runtime that runs on diffrent OS's. Set up the isolated environment for your container
:::

## Mode for running containers

+------------------------------------------------------------+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Mode                                                       | Run command       | Use case                                                                                                                                                                                                           |
+============================================================+===================+====================================================================================================================================================================================================================+
| Detached                                                   | `docker run -d`   | This runs the container in the **background** so the container keeps running until the application process exits, or you stop the container. Detached mode is often used for production purposes.                  |
+------------------------------------------------------------+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Interactive + terminal                                     | `docker run -it`  | This runs the container in the **foreground** so you are unable to access the command prompt. Interactive mode is often used for development and testing.                                                          |
+------------------------------------------------------------+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Remove everything once the container is done with its task | `docker run --rm` | This mode is used on foreground containers that perform **short-term tasks** such as tests or database backups. Once it is removed anything you may have downloaded or created in the container is also destroyed. |
+------------------------------------------------------------+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

## Lab Activity

üü• - I need help

üü® - I'm still working

üü© - I'm done

Complete Lab 2: Part 1

## Container Debugging

-   Interactive mode

-   `docker exec`

-   Logging

```         
docker run -it -d ubuntu
docker container ls -a 
docker exec -it CONTAINER_ID bash

docker container run -d --name mydb \
 --name mydb \
 -e MYSQL_ROOT_PASSWORD=my-secret-pw \ 
 mysql
 
 docker container logs mydb
```

::: footer
üîç Live code
:::

## Lab Activity

üü• - I need help

üü® - I'm still working

üü© - I'm done

Complete Lab 2: Part 2

## Port Mapping with `docker run -p`

```         
docker pull httpd:alpine
docker pull httpd:latest

docker inspect --format='{{.Config.ExposedPorts}}' httpd:latest
docker inspect --format='{{.Config.ExposedPorts}}' httpd:alpine

docker run -p DockerHostPort:ApplicationPort

docker run -d -p 81:80 --name httpd-latest httpd:latest
curl http://localhost:81

docker run -d -p 80:80 --name httpd-alpine httpd:alpine
curl http://localhost:80
```

::: footer
üîç Live code
:::

## Persisting data with Docker

Stateless vs. Stateful applications volume mount bind mount external storage shared file system

## Putting it all together

https://github.com/rstudio/rstudio-docker-products/blob/dev/docker-compose.yml

::: notes
-   **docker-compose:** A tool for defining and running multi-container Docker applications.
-   Uses a YAML file to define services, networks, and volumes.
-   Simplifies the orchestration of complex applications.
:::

## Lab Activity

üü• - I need help

üü® - I'm still working

üü© - I'm done

Complete Lab 2: Part 3 Complete Lab 2: Part 4

## Building Docker Images

-   Images are build using a Dockerfile or interactively "on-the-fly"

-   Steps to version and share your images on Dockerhub (or a different repository)

make this a diagram Step 1: Commit Step 2: Tag Step 3: Push

## Lab Activity

üü• - I need help

üü® - I'm still working

üü© - I'm done

Complete Lab 2: Part 5

## Dockerfile Build Commands

| Command | Description |
|---------|-------------|
| FROM    |             |
| ENV     |             |
| COPY    |             |
| RUN     |             |
|         |             |
|         |             |
|         |             |

## Dockerfile Example

Walk through Posit Connect [Dockerfile](https://github.com/rstudio/rstudio-docker-products/blob/dev/connect/Dockerfile.ubuntu2204)

## Activity

Complete Lab 2: Part 6

## Part 4: Data Science in Production

## Data Science in Production {.content-dark}

-   Presentation Layer

-   Processing Layer

-   Data store Layer

## Choosing the right presentation layer

-   [Alex's flow chart](https://do4ds.com/chapters/sec1/1-2-proj-arch.html)

-   credit text

## Production "State"

Questions to ask once your content is able to be consumed by your intended audience

-   Is it reproducible?

-   Is it portable?

-   Is it maintainable?

-   Does it scale?

-   Is your code efficiently written?

-   Is it secure and accessible?

-   Can you trust your code?

## APIs can help

-   RESTful APIs

-   a way to access content by non-R users

## Structure of an API

## Activity: Create a Posit Connect API key

-   login to Connect

-   create connect key

-   use rsconnect to access

-   use curl to access

## Creating an API

-   plumber exercise

## Securing your application

-   SSL & https

-   live code

## Authentication vs. Authorization

## Deploying and hosting your API

## Activity

-   deploy api to connect

-   put shiny frontend and call api

## Testing and logging

## Activity

-   add logging and test to shiny app (if there's time)

## Activity

-   add app to server

## 
